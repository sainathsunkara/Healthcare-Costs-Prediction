{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fcc_predict_health_costs_with_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, `model.evaluate` must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "f5f67414-9336-4a43-97a9-eeea972878f7"
      },
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-12 02:39:49--  https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.2.33, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50264 (49K) [text/csv]\n",
            "Saving to: ‘insurance.csv.1’\n",
            "\n",
            "\rinsurance.csv.1       0%[                    ]       0  --.-KB/s               \rinsurance.csv.1     100%[===================>]  49.09K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-09-12 02:39:49 (5.40 MB/s) - ‘insurance.csv.1’ saved [50264/50264]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex   bmi  children smoker     region  expenses\n",
              "1333   50    male  31.0         3     no  northwest  10600.55\n",
              "1334   18  female  31.9         0     no  northeast   2205.98\n",
              "1335   18  female  36.9         0     no  southeast   1629.83\n",
              "1336   21  female  25.8         0     no  southwest   2007.95\n",
              "1337   61  female  29.1         0    yes  northwest  29141.36"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "1bcf998e-0adc-4f5d-dc13-5fb96aff3c9f"
      },
      "source": [
        "catColumns = [\"sex\", \"smoker\", \"region\"]\n",
        "dataset = pd.get_dummies(dataset, columns = catColumns, drop_first=True)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>expenses</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age   bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.9         0  ...                 0                 0                 1\n",
              "1   18  33.8         1  ...                 0                 1                 0\n",
              "2   28  33.0         3  ...                 0                 1                 0\n",
              "3   33  22.7         0  ...                 1                 0                 0\n",
              "4   32  28.9         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3_70zSWs_py"
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "test_labels = test_dataset.pop(\"expenses\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqAvhFMqtCxB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3a326711-f6af-41b5-de82-d6d5c103414e"
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>39.036449</td>\n",
              "      <td>14.142122</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>30.737290</td>\n",
              "      <td>6.065193</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>30.5</td>\n",
              "      <td>34.8</td>\n",
              "      <td>53.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>1.093458</td>\n",
              "      <td>1.211364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_male</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.498131</td>\n",
              "      <td>0.500230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker_yes</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.199065</td>\n",
              "      <td>0.399484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_northwest</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.235514</td>\n",
              "      <td>0.424518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southeast</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.281308</td>\n",
              "      <td>0.449848</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southwest</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.234579</td>\n",
              "      <td>0.423934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   count       mean        std   min   25%   50%   75%   max\n",
              "age               1070.0  39.036449  14.142122  18.0  26.0  39.0  51.0  64.0\n",
              "bmi               1070.0  30.737290   6.065193  16.0  26.3  30.5  34.8  53.1\n",
              "children          1070.0   1.093458   1.211364   0.0   0.0   1.0   2.0   5.0\n",
              "sex_male          1070.0   0.498131   0.500230   0.0   0.0   0.0   1.0   1.0\n",
              "smoker_yes        1070.0   0.199065   0.399484   0.0   0.0   0.0   0.0   1.0\n",
              "region_northwest  1070.0   0.235514   0.424518   0.0   0.0   0.0   0.0   1.0\n",
              "region_southeast  1070.0   0.281308   0.449848   0.0   0.0   0.0   1.0   1.0\n",
              "region_southwest  1070.0   0.234579   0.423934   0.0   0.0   0.0   0.0   1.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apx1BeGlt88P"
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2yirCqZuGEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af8a4a5-cb79-49ce-ccf3-85838337afc0"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1, activation='relu')\n",
        "  ])\n",
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "model.compile(loss='mae',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['mae','mse'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 128)               1152      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 16,193\n",
            "Trainable params: 16,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfuTz_ANuHjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613af4f5-a6c0-461a-9c2b-a6f0ae3832b4"
      },
      "source": [
        "EPOCHS = 1000\n",
        "history = model.fit(train_dataset, train_labels, epochs=EPOCHS, validation_split = 0.2, verbose=1, callbacks=[tf.keras.callbacks.ModelCheckpoint(\"./checkpoint\", save_best_only=True, monitor='val_loss')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "27/27 [==============================] - 1s 10ms/step - loss: 12346.5400 - mae: 12346.5400 - mse: 291910464.0000 - val_loss: 12981.4297 - val_mae: 12981.4297 - val_mse: 321804608.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 2/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8940.2305 - mae: 8940.2305 - mse: 205793840.0000 - val_loss: 7866.6348 - val_mae: 7866.6348 - val_mse: 180859344.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 3/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7033.4053 - mae: 7033.4053 - mse: 144838688.0000 - val_loss: 7825.4614 - val_mae: 7825.4614 - val_mse: 184093712.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 4/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6943.7793 - mae: 6943.7793 - mse: 146940112.0000 - val_loss: 7728.0171 - val_mae: 7728.0171 - val_mse: 184937456.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 5/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6842.9536 - mae: 6842.9536 - mse: 147907216.0000 - val_loss: 7644.7061 - val_mae: 7644.7061 - val_mse: 186160208.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 6/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6743.0415 - mae: 6743.0415 - mse: 148415744.0000 - val_loss: 7710.5747 - val_mae: 7710.5747 - val_mse: 194102736.0000\n",
            "Epoch 7/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6640.5317 - mae: 6640.5317 - mse: 149882752.0000 - val_loss: 7495.6123 - val_mae: 7495.6123 - val_mse: 190498000.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 8/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6544.3213 - mae: 6544.3213 - mse: 150857440.0000 - val_loss: 7456.7651 - val_mae: 7456.7651 - val_mse: 193710064.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 9/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6452.3115 - mae: 6452.3115 - mse: 152152416.0000 - val_loss: 7549.2568 - val_mae: 7549.2568 - val_mse: 199916688.0000\n",
            "Epoch 10/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6388.1738 - mae: 6388.1738 - mse: 152882896.0000 - val_loss: 7251.3433 - val_mae: 7251.3433 - val_mse: 189902784.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 11/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6346.0591 - mae: 6346.0591 - mse: 153629280.0000 - val_loss: 7284.8696 - val_mae: 7284.8696 - val_mse: 195282240.0000\n",
            "Epoch 12/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6317.4692 - mae: 6317.4692 - mse: 153081280.0000 - val_loss: 7419.5913 - val_mae: 7419.5913 - val_mse: 200478240.0000\n",
            "Epoch 13/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6312.1597 - mae: 6312.1597 - mse: 154438960.0000 - val_loss: 7306.4556 - val_mae: 7306.4556 - val_mse: 197258512.0000\n",
            "Epoch 14/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6290.1943 - mae: 6290.1943 - mse: 153893488.0000 - val_loss: 7311.1167 - val_mae: 7311.1167 - val_mse: 197875312.0000\n",
            "Epoch 15/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6270.4146 - mae: 6270.4146 - mse: 152720304.0000 - val_loss: 7492.2988 - val_mae: 7492.2983 - val_mse: 202310288.0000\n",
            "Epoch 16/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6260.2065 - mae: 6260.2065 - mse: 152890864.0000 - val_loss: 7160.5625 - val_mae: 7160.5625 - val_mse: 187269728.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 17/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6248.5366 - mae: 6248.5366 - mse: 152147088.0000 - val_loss: 7146.6655 - val_mae: 7146.6655 - val_mse: 186961904.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 18/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6243.6333 - mae: 6243.6333 - mse: 152302368.0000 - val_loss: 7133.1484 - val_mae: 7133.1484 - val_mse: 186847264.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 19/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6238.1655 - mae: 6238.1655 - mse: 152149344.0000 - val_loss: 7183.3164 - val_mae: 7183.3164 - val_mse: 193580800.0000\n",
            "Epoch 20/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6203.8125 - mae: 6203.8125 - mse: 151771312.0000 - val_loss: 7125.8887 - val_mae: 7125.8887 - val_mse: 183351008.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 21/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6192.2476 - mae: 6192.2476 - mse: 150945280.0000 - val_loss: 7088.4683 - val_mae: 7088.4683 - val_mse: 186258192.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 22/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6180.6880 - mae: 6180.6880 - mse: 151133936.0000 - val_loss: 7073.6182 - val_mae: 7073.6182 - val_mse: 186321008.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 23/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6164.5449 - mae: 6164.5449 - mse: 149960992.0000 - val_loss: 7060.0518 - val_mae: 7060.0518 - val_mse: 186947872.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 24/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6160.7896 - mae: 6160.7896 - mse: 149636400.0000 - val_loss: 7123.4473 - val_mae: 7123.4473 - val_mse: 191814320.0000\n",
            "Epoch 25/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6141.1553 - mae: 6141.1553 - mse: 149039184.0000 - val_loss: 7055.7886 - val_mae: 7055.7886 - val_mse: 188590592.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 26/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6113.3965 - mae: 6113.3965 - mse: 149029520.0000 - val_loss: 7025.0464 - val_mae: 7025.0464 - val_mse: 179521520.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 27/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6123.5762 - mae: 6123.5762 - mse: 147347488.0000 - val_loss: 6986.4756 - val_mae: 6986.4756 - val_mse: 183855168.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 28/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6088.8516 - mae: 6088.8516 - mse: 147255376.0000 - val_loss: 7018.8154 - val_mae: 7018.8154 - val_mse: 187743280.0000\n",
            "Epoch 29/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6050.9824 - mae: 6050.9824 - mse: 146056144.0000 - val_loss: 7014.5420 - val_mae: 7014.5420 - val_mse: 187606832.0000\n",
            "Epoch 30/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6045.4414 - mae: 6045.4414 - mse: 146086608.0000 - val_loss: 7025.8149 - val_mae: 7025.8149 - val_mse: 187737552.0000\n",
            "Epoch 31/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6043.8130 - mae: 6043.8130 - mse: 145671616.0000 - val_loss: 6894.6191 - val_mae: 6894.6191 - val_mse: 180496912.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 32/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6000.9082 - mae: 6000.9082 - mse: 144670176.0000 - val_loss: 6882.4385 - val_mae: 6882.4385 - val_mse: 174363232.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 33/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5977.0928 - mae: 5977.0928 - mse: 142940080.0000 - val_loss: 6846.3745 - val_mae: 6846.3745 - val_mse: 173601824.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 34/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5962.0054 - mae: 5962.0054 - mse: 142543008.0000 - val_loss: 6812.7554 - val_mae: 6812.7554 - val_mse: 178211952.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 35/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5943.7661 - mae: 5943.7661 - mse: 141372480.0000 - val_loss: 6892.1260 - val_mae: 6892.1260 - val_mse: 182644320.0000\n",
            "Epoch 36/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5903.5098 - mae: 5903.5098 - mse: 140136480.0000 - val_loss: 6740.6797 - val_mae: 6740.6797 - val_mse: 170295216.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 37/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5882.4722 - mae: 5882.4722 - mse: 139454112.0000 - val_loss: 6721.2422 - val_mae: 6721.2422 - val_mse: 175129744.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 38/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5860.5518 - mae: 5860.5518 - mse: 138338096.0000 - val_loss: 6774.9175 - val_mae: 6774.9175 - val_mse: 177716576.0000\n",
            "Epoch 39/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5818.4941 - mae: 5818.4941 - mse: 136941472.0000 - val_loss: 6622.9497 - val_mae: 6622.9497 - val_mse: 169885856.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 40/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5799.6113 - mae: 5799.6113 - mse: 135500768.0000 - val_loss: 6670.2549 - val_mae: 6670.2549 - val_mse: 173217952.0000\n",
            "Epoch 41/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5743.2212 - mae: 5743.2212 - mse: 134095440.0000 - val_loss: 6581.6758 - val_mae: 6581.6758 - val_mse: 169604816.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 42/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5687.7759 - mae: 5687.7759 - mse: 131889968.0000 - val_loss: 6929.4038 - val_mae: 6929.4038 - val_mse: 176187872.0000\n",
            "Epoch 43/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5654.0845 - mae: 5654.0845 - mse: 130019408.0000 - val_loss: 6434.5171 - val_mae: 6434.5171 - val_mse: 162790032.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 44/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5628.1665 - mae: 5628.1665 - mse: 128299208.0000 - val_loss: 6339.7036 - val_mae: 6339.7036 - val_mse: 157352432.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 45/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5551.4668 - mae: 5551.4668 - mse: 125714952.0000 - val_loss: 6329.9932 - val_mae: 6329.9932 - val_mse: 147170672.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 46/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5505.2046 - mae: 5505.2046 - mse: 122930472.0000 - val_loss: 6225.7012 - val_mae: 6225.7012 - val_mse: 153169120.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 47/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5437.6973 - mae: 5437.6973 - mse: 120848784.0000 - val_loss: 6193.2925 - val_mae: 6193.2925 - val_mse: 152138176.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 48/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5362.8306 - mae: 5362.8306 - mse: 116158792.0000 - val_loss: 6316.6133 - val_mae: 6316.6133 - val_mse: 153270640.0000\n",
            "Epoch 49/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5265.2441 - mae: 5265.2441 - mse: 112985088.0000 - val_loss: 5860.3804 - val_mae: 5860.3804 - val_mse: 134927920.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 50/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5146.0454 - mae: 5146.0454 - mse: 107488936.0000 - val_loss: 5907.6670 - val_mae: 5907.6670 - val_mse: 138155840.0000\n",
            "Epoch 51/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5017.6821 - mae: 5017.6821 - mse: 103283744.0000 - val_loss: 5488.0039 - val_mae: 5488.0039 - val_mse: 119711192.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 52/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4892.9692 - mae: 4892.9692 - mse: 95844728.0000 - val_loss: 5418.8193 - val_mae: 5418.8193 - val_mse: 107917448.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 53/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4670.5835 - mae: 4670.5835 - mse: 88622952.0000 - val_loss: 5032.7637 - val_mae: 5032.7637 - val_mse: 106009552.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 54/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4500.2524 - mae: 4500.2524 - mse: 81817840.0000 - val_loss: 4778.9683 - val_mae: 4778.9683 - val_mse: 96732696.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 55/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4300.4829 - mae: 4300.4829 - mse: 74079928.0000 - val_loss: 5533.3623 - val_mae: 5533.3623 - val_mse: 105960480.0000\n",
            "Epoch 56/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4150.0283 - mae: 4150.0283 - mse: 69559824.0000 - val_loss: 4386.0869 - val_mae: 4386.0869 - val_mse: 81366744.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 57/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4031.2458 - mae: 4031.2458 - mse: 64404144.0000 - val_loss: 4349.6401 - val_mae: 4349.6401 - val_mse: 72358400.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 58/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3893.0088 - mae: 3893.0088 - mse: 60724232.0000 - val_loss: 4197.7861 - val_mae: 4197.7861 - val_mse: 67840152.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 59/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3794.4270 - mae: 3794.4270 - mse: 55956096.0000 - val_loss: 4095.6863 - val_mae: 4095.6863 - val_mse: 68007024.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 60/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3736.9080 - mae: 3736.9080 - mse: 54236784.0000 - val_loss: 3973.1289 - val_mae: 3973.1289 - val_mse: 64112460.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 61/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3717.2312 - mae: 3717.2312 - mse: 53359720.0000 - val_loss: 4579.7510 - val_mae: 4579.7510 - val_mse: 54895964.0000\n",
            "Epoch 62/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3716.9524 - mae: 3716.9524 - mse: 51905320.0000 - val_loss: 4437.5381 - val_mae: 4437.5381 - val_mse: 54641880.0000\n",
            "Epoch 63/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3682.2822 - mae: 3682.2822 - mse: 50825028.0000 - val_loss: 4408.2759 - val_mae: 4408.2759 - val_mse: 53076404.0000\n",
            "Epoch 64/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3613.7241 - mae: 3613.7241 - mse: 48101400.0000 - val_loss: 4855.5054 - val_mae: 4855.5054 - val_mse: 72935136.0000\n",
            "Epoch 65/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3687.1226 - mae: 3687.1226 - mse: 48800644.0000 - val_loss: 3891.3730 - val_mae: 3891.3730 - val_mse: 58082064.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 66/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3627.3003 - mae: 3627.3003 - mse: 47744764.0000 - val_loss: 4260.9067 - val_mae: 4260.9067 - val_mse: 50249664.0000\n",
            "Epoch 67/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3629.5093 - mae: 3629.5093 - mse: 45128708.0000 - val_loss: 3993.0242 - val_mae: 3993.0242 - val_mse: 58211300.0000\n",
            "Epoch 68/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3630.9543 - mae: 3630.9543 - mse: 45923552.0000 - val_loss: 4172.0376 - val_mae: 4172.0376 - val_mse: 58612476.0000\n",
            "Epoch 69/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3544.8821 - mae: 3544.8821 - mse: 43781192.0000 - val_loss: 3838.6606 - val_mae: 3838.6606 - val_mse: 48442984.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 70/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3578.7854 - mae: 3578.7854 - mse: 43176304.0000 - val_loss: 4410.3262 - val_mae: 4410.3262 - val_mse: 44712024.0000\n",
            "Epoch 71/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3554.4314 - mae: 3554.4314 - mse: 41111232.0000 - val_loss: 3795.0898 - val_mae: 3795.0898 - val_mse: 49782244.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 72/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3554.8057 - mae: 3554.8057 - mse: 40987364.0000 - val_loss: 3750.4299 - val_mae: 3750.4299 - val_mse: 47775992.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 73/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3457.2893 - mae: 3457.2893 - mse: 39139216.0000 - val_loss: 3626.4600 - val_mae: 3626.4600 - val_mse: 44559476.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 74/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3483.5027 - mae: 3483.5027 - mse: 37885616.0000 - val_loss: 3634.3516 - val_mae: 3634.3516 - val_mse: 42753364.0000\n",
            "Epoch 75/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3481.6870 - mae: 3481.6870 - mse: 37950196.0000 - val_loss: 3843.2651 - val_mae: 3843.2651 - val_mse: 41005368.0000\n",
            "Epoch 76/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3510.5779 - mae: 3510.5779 - mse: 37736780.0000 - val_loss: 3990.2183 - val_mae: 3990.2183 - val_mse: 45831724.0000\n",
            "Epoch 77/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3394.7146 - mae: 3394.7146 - mse: 37029956.0000 - val_loss: 4126.9341 - val_mae: 4126.9341 - val_mse: 45907360.0000\n",
            "Epoch 78/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3422.9839 - mae: 3422.9839 - mse: 37089604.0000 - val_loss: 4051.5725 - val_mae: 4051.5725 - val_mse: 41290344.0000\n",
            "Epoch 79/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3372.0381 - mae: 3372.0381 - mse: 36319668.0000 - val_loss: 3458.3914 - val_mae: 3458.3914 - val_mse: 40912724.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 80/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3391.1414 - mae: 3391.1414 - mse: 36729036.0000 - val_loss: 3534.8376 - val_mae: 3534.8376 - val_mse: 41480288.0000\n",
            "Epoch 81/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3377.4280 - mae: 3377.4280 - mse: 37590964.0000 - val_loss: 3728.3640 - val_mae: 3728.3640 - val_mse: 42541552.0000\n",
            "Epoch 82/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3341.2510 - mae: 3341.2510 - mse: 37779324.0000 - val_loss: 3766.6543 - val_mae: 3766.6543 - val_mse: 43310984.0000\n",
            "Epoch 83/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3322.9116 - mae: 3322.9116 - mse: 39358564.0000 - val_loss: 3460.2041 - val_mae: 3460.2041 - val_mse: 43586152.0000\n",
            "Epoch 84/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3246.8577 - mae: 3246.8577 - mse: 39578144.0000 - val_loss: 3432.6245 - val_mae: 3432.6245 - val_mse: 44346212.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 85/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3286.3174 - mae: 3286.3174 - mse: 39337384.0000 - val_loss: 3311.8115 - val_mae: 3311.8115 - val_mse: 42537296.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 86/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3241.3467 - mae: 3241.3467 - mse: 40176080.0000 - val_loss: 3860.1716 - val_mae: 3860.1716 - val_mse: 43289716.0000\n",
            "Epoch 87/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3293.4058 - mae: 3293.4058 - mse: 39800176.0000 - val_loss: 3353.2041 - val_mae: 3353.2041 - val_mse: 42170944.0000\n",
            "Epoch 88/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3249.7664 - mae: 3249.7664 - mse: 40280328.0000 - val_loss: 3380.1516 - val_mae: 3380.1516 - val_mse: 42950908.0000\n",
            "Epoch 89/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3212.0232 - mae: 3212.0232 - mse: 39289836.0000 - val_loss: 3418.1221 - val_mae: 3418.1221 - val_mse: 42118460.0000\n",
            "Epoch 90/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3243.9424 - mae: 3243.9424 - mse: 40457756.0000 - val_loss: 3355.2429 - val_mae: 3355.2429 - val_mse: 41210556.0000\n",
            "Epoch 91/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3217.4697 - mae: 3217.4697 - mse: 39542488.0000 - val_loss: 3267.6121 - val_mae: 3267.6121 - val_mse: 40941992.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 92/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3235.0437 - mae: 3235.0437 - mse: 38995340.0000 - val_loss: 4167.1938 - val_mae: 4167.1938 - val_mse: 50387048.0000\n",
            "Epoch 93/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3193.0896 - mae: 3193.0896 - mse: 39262896.0000 - val_loss: 3212.8523 - val_mae: 3212.8523 - val_mse: 42220012.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 94/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3226.2605 - mae: 3226.2605 - mse: 39709336.0000 - val_loss: 3471.0698 - val_mae: 3471.0698 - val_mse: 40718064.0000\n",
            "Epoch 95/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3184.9832 - mae: 3184.9832 - mse: 40153624.0000 - val_loss: 3871.2751 - val_mae: 3871.2751 - val_mse: 41023868.0000\n",
            "Epoch 96/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3180.2212 - mae: 3180.2212 - mse: 39189988.0000 - val_loss: 3580.2471 - val_mae: 3580.2471 - val_mse: 44060648.0000\n",
            "Epoch 97/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3152.4878 - mae: 3152.4878 - mse: 38916200.0000 - val_loss: 3117.2319 - val_mae: 3117.2319 - val_mse: 40831324.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 98/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3163.6260 - mae: 3163.6260 - mse: 38690856.0000 - val_loss: 3428.2568 - val_mae: 3428.2568 - val_mse: 38929452.0000\n",
            "Epoch 99/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3189.5845 - mae: 3189.5845 - mse: 37722380.0000 - val_loss: 4146.3779 - val_mae: 4146.3779 - val_mse: 49430608.0000\n",
            "Epoch 100/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3128.1260 - mae: 3128.1260 - mse: 39147876.0000 - val_loss: 3289.2515 - val_mae: 3289.2515 - val_mse: 39451836.0000\n",
            "Epoch 101/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3155.3030 - mae: 3155.3030 - mse: 38449796.0000 - val_loss: 3065.5391 - val_mae: 3065.5391 - val_mse: 39624576.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 102/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3113.3914 - mae: 3113.3914 - mse: 38814312.0000 - val_loss: 3082.5779 - val_mae: 3082.5779 - val_mse: 39224188.0000\n",
            "Epoch 103/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3162.1458 - mae: 3162.1458 - mse: 37989552.0000 - val_loss: 3574.3391 - val_mae: 3574.3391 - val_mse: 39244224.0000\n",
            "Epoch 104/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3120.9014 - mae: 3120.9014 - mse: 38298924.0000 - val_loss: 3121.7981 - val_mae: 3121.7981 - val_mse: 38982844.0000\n",
            "Epoch 105/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3124.7673 - mae: 3124.7673 - mse: 37607704.0000 - val_loss: 3203.5620 - val_mae: 3203.5620 - val_mse: 39699244.0000\n",
            "Epoch 106/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3148.4795 - mae: 3148.4795 - mse: 38004552.0000 - val_loss: 3100.1667 - val_mae: 3100.1667 - val_mse: 37825820.0000\n",
            "Epoch 107/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3104.3611 - mae: 3104.3611 - mse: 37534228.0000 - val_loss: 2998.7888 - val_mae: 2998.7888 - val_mse: 37902356.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 108/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3113.6514 - mae: 3113.6514 - mse: 38118188.0000 - val_loss: 2945.5598 - val_mae: 2945.5598 - val_mse: 37757956.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 109/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3062.3635 - mae: 3062.3635 - mse: 37233308.0000 - val_loss: 3425.1116 - val_mae: 3425.1116 - val_mse: 40651060.0000\n",
            "Epoch 110/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3026.2275 - mae: 3026.2275 - mse: 36815448.0000 - val_loss: 3134.8391 - val_mae: 3134.8391 - val_mse: 38499748.0000\n",
            "Epoch 111/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3057.8533 - mae: 3057.8533 - mse: 37317312.0000 - val_loss: 3022.2563 - val_mae: 3022.2563 - val_mse: 35743576.0000\n",
            "Epoch 112/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3111.9866 - mae: 3111.9866 - mse: 37051600.0000 - val_loss: 2988.3120 - val_mae: 2988.3120 - val_mse: 35419448.0000\n",
            "Epoch 113/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3080.4253 - mae: 3080.4253 - mse: 36318976.0000 - val_loss: 3037.8691 - val_mae: 3037.8691 - val_mse: 36288540.0000\n",
            "Epoch 114/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3034.5339 - mae: 3034.5339 - mse: 36391212.0000 - val_loss: 2981.1426 - val_mae: 2981.1426 - val_mse: 35253496.0000\n",
            "Epoch 115/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3071.8530 - mae: 3071.8530 - mse: 36409500.0000 - val_loss: 2882.4336 - val_mae: 2882.4336 - val_mse: 35863068.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 116/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3035.2363 - mae: 3035.2363 - mse: 36782940.0000 - val_loss: 3584.5967 - val_mae: 3584.5967 - val_mse: 36834696.0000\n",
            "Epoch 117/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2990.6116 - mae: 2990.6116 - mse: 35455432.0000 - val_loss: 3384.1477 - val_mae: 3384.1477 - val_mse: 39208440.0000\n",
            "Epoch 118/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3008.7527 - mae: 3008.7527 - mse: 35699704.0000 - val_loss: 2905.2305 - val_mae: 2905.2305 - val_mse: 34679372.0000\n",
            "Epoch 119/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3054.2144 - mae: 3054.2144 - mse: 36297980.0000 - val_loss: 2958.0271 - val_mae: 2958.0271 - val_mse: 34496336.0000\n",
            "Epoch 120/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2975.4812 - mae: 2975.4812 - mse: 35232688.0000 - val_loss: 2913.3850 - val_mae: 2913.3850 - val_mse: 34343284.0000\n",
            "Epoch 121/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2991.7383 - mae: 2991.7383 - mse: 36308236.0000 - val_loss: 2872.9170 - val_mae: 2872.9170 - val_mse: 33204284.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 122/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3036.3057 - mae: 3036.3057 - mse: 35748472.0000 - val_loss: 2822.3545 - val_mae: 2822.3545 - val_mse: 35725560.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 123/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2981.8477 - mae: 2981.8477 - mse: 35746528.0000 - val_loss: 2895.0625 - val_mae: 2895.0625 - val_mse: 33439192.0000\n",
            "Epoch 124/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2992.5764 - mae: 2992.5764 - mse: 35545536.0000 - val_loss: 2861.5405 - val_mae: 2861.5405 - val_mse: 33692528.0000\n",
            "Epoch 125/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2942.4407 - mae: 2942.4407 - mse: 35057296.0000 - val_loss: 2799.0217 - val_mae: 2799.0217 - val_mse: 34307592.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 126/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2965.7383 - mae: 2965.7383 - mse: 36039836.0000 - val_loss: 3317.3000 - val_mae: 3317.3000 - val_mse: 36077668.0000\n",
            "Epoch 127/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2929.8350 - mae: 2929.8350 - mse: 35555240.0000 - val_loss: 3105.4915 - val_mae: 3105.4915 - val_mse: 34569100.0000\n",
            "Epoch 128/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2964.7214 - mae: 2964.7214 - mse: 35684672.0000 - val_loss: 2862.7339 - val_mae: 2862.7339 - val_mse: 34535844.0000\n",
            "Epoch 129/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2957.9929 - mae: 2957.9929 - mse: 35856588.0000 - val_loss: 3022.9355 - val_mae: 3022.9355 - val_mse: 34647888.0000\n",
            "Epoch 130/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2993.2861 - mae: 2993.2861 - mse: 35819900.0000 - val_loss: 2995.1487 - val_mae: 2995.1487 - val_mse: 33229776.0000\n",
            "Epoch 131/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2933.1101 - mae: 2933.1101 - mse: 34869172.0000 - val_loss: 2794.8347 - val_mae: 2794.8347 - val_mse: 33032542.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 132/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2949.2842 - mae: 2949.2842 - mse: 35445616.0000 - val_loss: 2775.6697 - val_mae: 2775.6697 - val_mse: 32373272.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 133/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2928.9839 - mae: 2928.9839 - mse: 35471548.0000 - val_loss: 3417.3245 - val_mae: 3417.3245 - val_mse: 34862744.0000\n",
            "Epoch 134/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2917.1230 - mae: 2917.1230 - mse: 35533644.0000 - val_loss: 2930.8335 - val_mae: 2930.8335 - val_mse: 33442028.0000\n",
            "Epoch 135/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2907.2070 - mae: 2907.2070 - mse: 34266904.0000 - val_loss: 2769.5081 - val_mae: 2769.5081 - val_mse: 33104496.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 136/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2875.1284 - mae: 2875.1284 - mse: 35007492.0000 - val_loss: 3062.1621 - val_mae: 3062.1621 - val_mse: 36108760.0000\n",
            "Epoch 137/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2945.3645 - mae: 2945.3645 - mse: 35298016.0000 - val_loss: 3283.9255 - val_mae: 3283.9255 - val_mse: 37553796.0000\n",
            "Epoch 138/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2900.7400 - mae: 2900.7400 - mse: 34530860.0000 - val_loss: 2725.6150 - val_mae: 2725.6150 - val_mse: 32003990.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 139/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2910.0354 - mae: 2910.0354 - mse: 34588872.0000 - val_loss: 2985.3105 - val_mae: 2985.3105 - val_mse: 33361480.0000\n",
            "Epoch 140/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2825.8271 - mae: 2825.8271 - mse: 34149256.0000 - val_loss: 2904.7654 - val_mae: 2904.7654 - val_mse: 33332564.0000\n",
            "Epoch 141/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2909.5144 - mae: 2909.5144 - mse: 34433296.0000 - val_loss: 2808.3245 - val_mae: 2808.3245 - val_mse: 33773080.0000\n",
            "Epoch 142/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2845.7573 - mae: 2845.7573 - mse: 34085656.0000 - val_loss: 2777.8909 - val_mae: 2777.8909 - val_mse: 32577670.0000\n",
            "Epoch 143/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2821.2668 - mae: 2821.2668 - mse: 34072628.0000 - val_loss: 2799.4387 - val_mae: 2799.4387 - val_mse: 32909990.0000\n",
            "Epoch 144/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2842.6909 - mae: 2842.6909 - mse: 33692500.0000 - val_loss: 3184.6282 - val_mae: 3184.6282 - val_mse: 34367468.0000\n",
            "Epoch 145/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2848.9866 - mae: 2848.9866 - mse: 33637056.0000 - val_loss: 3083.1418 - val_mae: 3083.1418 - val_mse: 32662030.0000\n",
            "Epoch 146/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2897.8804 - mae: 2897.8804 - mse: 34265512.0000 - val_loss: 2856.8704 - val_mae: 2856.8704 - val_mse: 33920976.0000\n",
            "Epoch 147/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2781.4905 - mae: 2781.4905 - mse: 33827116.0000 - val_loss: 2694.0413 - val_mae: 2694.0413 - val_mse: 32459144.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 148/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2797.3972 - mae: 2797.3972 - mse: 33479920.0000 - val_loss: 2760.8391 - val_mae: 2760.8391 - val_mse: 31790922.0000\n",
            "Epoch 149/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2881.5657 - mae: 2881.5657 - mse: 34517064.0000 - val_loss: 2725.6907 - val_mae: 2725.6907 - val_mse: 30970452.0000\n",
            "Epoch 150/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2783.3770 - mae: 2783.3770 - mse: 33047988.0000 - val_loss: 2896.9875 - val_mae: 2896.9875 - val_mse: 34207680.0000\n",
            "Epoch 151/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2782.8889 - mae: 2782.8889 - mse: 33665968.0000 - val_loss: 2809.4734 - val_mae: 2809.4734 - val_mse: 32595882.0000\n",
            "Epoch 152/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2805.0667 - mae: 2805.0667 - mse: 33376832.0000 - val_loss: 2936.2124 - val_mae: 2936.2124 - val_mse: 32714752.0000\n",
            "Epoch 153/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2752.0693 - mae: 2752.0693 - mse: 32868356.0000 - val_loss: 3410.9460 - val_mae: 3410.9460 - val_mse: 34156588.0000\n",
            "Epoch 154/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2773.5193 - mae: 2773.5193 - mse: 33432956.0000 - val_loss: 2622.0789 - val_mae: 2622.0789 - val_mse: 31128284.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 155/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2733.7744 - mae: 2733.7744 - mse: 32667258.0000 - val_loss: 2836.5669 - val_mae: 2836.5669 - val_mse: 30866592.0000\n",
            "Epoch 156/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2718.9592 - mae: 2718.9592 - mse: 32775054.0000 - val_loss: 2612.4314 - val_mae: 2612.4314 - val_mse: 32798298.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 157/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2831.5227 - mae: 2831.5227 - mse: 34302048.0000 - val_loss: 2941.4983 - val_mae: 2941.4983 - val_mse: 33268866.0000\n",
            "Epoch 158/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2776.3794 - mae: 2776.3794 - mse: 33579504.0000 - val_loss: 2642.4224 - val_mae: 2642.4224 - val_mse: 30788802.0000\n",
            "Epoch 159/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2740.8789 - mae: 2740.8789 - mse: 33128298.0000 - val_loss: 2620.9346 - val_mae: 2620.9346 - val_mse: 30396230.0000\n",
            "Epoch 160/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2794.9885 - mae: 2794.9885 - mse: 33585560.0000 - val_loss: 2873.2869 - val_mae: 2873.2869 - val_mse: 31318828.0000\n",
            "Epoch 161/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2735.4824 - mae: 2735.4824 - mse: 33369714.0000 - val_loss: 2617.5435 - val_mae: 2617.5435 - val_mse: 30072134.0000\n",
            "Epoch 162/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2768.2874 - mae: 2768.2874 - mse: 32826174.0000 - val_loss: 2572.9988 - val_mae: 2572.9988 - val_mse: 29996652.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 163/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2704.7708 - mae: 2704.7708 - mse: 32495546.0000 - val_loss: 2849.1604 - val_mae: 2849.1604 - val_mse: 31359240.0000\n",
            "Epoch 164/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2723.8008 - mae: 2723.8008 - mse: 32555446.0000 - val_loss: 3102.8328 - val_mae: 3102.8328 - val_mse: 32299630.0000\n",
            "Epoch 165/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2740.2659 - mae: 2740.2659 - mse: 32722262.0000 - val_loss: 2607.1125 - val_mae: 2607.1125 - val_mse: 29821840.0000\n",
            "Epoch 166/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2712.9258 - mae: 2712.9258 - mse: 32458504.0000 - val_loss: 2785.1338 - val_mae: 2785.1338 - val_mse: 30397536.0000\n",
            "Epoch 167/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2733.2766 - mae: 2733.2766 - mse: 32774704.0000 - val_loss: 2798.1753 - val_mae: 2798.1753 - val_mse: 30660318.0000\n",
            "Epoch 168/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2708.4348 - mae: 2708.4348 - mse: 32314868.0000 - val_loss: 2905.1782 - val_mae: 2905.1782 - val_mse: 31182070.0000\n",
            "Epoch 169/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2737.7561 - mae: 2737.7561 - mse: 31674964.0000 - val_loss: 2669.3367 - val_mae: 2669.3367 - val_mse: 30433404.0000\n",
            "Epoch 170/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2671.8838 - mae: 2671.8838 - mse: 31995868.0000 - val_loss: 2550.6309 - val_mae: 2550.6309 - val_mse: 29568776.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 171/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2640.2920 - mae: 2640.2920 - mse: 31849616.0000 - val_loss: 2636.7974 - val_mae: 2636.7974 - val_mse: 29556932.0000\n",
            "Epoch 172/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2675.6321 - mae: 2675.6321 - mse: 31920374.0000 - val_loss: 2658.3357 - val_mae: 2658.3357 - val_mse: 29347606.0000\n",
            "Epoch 173/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2665.0068 - mae: 2665.0068 - mse: 31510816.0000 - val_loss: 2662.0994 - val_mae: 2662.0994 - val_mse: 28648742.0000\n",
            "Epoch 174/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2636.0115 - mae: 2636.0115 - mse: 31501780.0000 - val_loss: 2504.1765 - val_mae: 2504.1765 - val_mse: 29363990.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 175/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2682.6870 - mae: 2682.6870 - mse: 31904690.0000 - val_loss: 2522.3254 - val_mae: 2522.3254 - val_mse: 29966922.0000\n",
            "Epoch 176/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2643.1355 - mae: 2643.1355 - mse: 31757474.0000 - val_loss: 2612.7595 - val_mae: 2612.7595 - val_mse: 29543596.0000\n",
            "Epoch 177/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2632.4436 - mae: 2632.4436 - mse: 31262868.0000 - val_loss: 2529.9983 - val_mae: 2529.9983 - val_mse: 29728684.0000\n",
            "Epoch 178/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2599.1399 - mae: 2599.1399 - mse: 30732546.0000 - val_loss: 2883.8440 - val_mae: 2883.8440 - val_mse: 30887980.0000\n",
            "Epoch 179/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2667.8435 - mae: 2667.8435 - mse: 32168994.0000 - val_loss: 2524.1104 - val_mae: 2524.1104 - val_mse: 29066788.0000\n",
            "Epoch 180/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2611.0420 - mae: 2611.0420 - mse: 30151000.0000 - val_loss: 3002.1741 - val_mae: 3002.1741 - val_mse: 31035918.0000\n",
            "Epoch 181/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2589.1182 - mae: 2589.1182 - mse: 30416430.0000 - val_loss: 2576.9641 - val_mae: 2576.9641 - val_mse: 29232018.0000\n",
            "Epoch 182/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2677.2754 - mae: 2677.2754 - mse: 31651098.0000 - val_loss: 2772.1418 - val_mae: 2772.1418 - val_mse: 29579900.0000\n",
            "Epoch 183/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2595.1741 - mae: 2595.1741 - mse: 30501194.0000 - val_loss: 2515.9790 - val_mae: 2515.9790 - val_mse: 28358502.0000\n",
            "Epoch 184/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2590.1282 - mae: 2590.1282 - mse: 30529502.0000 - val_loss: 3190.3630 - val_mae: 3190.3630 - val_mse: 32407710.0000\n",
            "Epoch 185/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2545.9136 - mae: 2545.9136 - mse: 29757528.0000 - val_loss: 2678.0330 - val_mae: 2678.0330 - val_mse: 29291676.0000\n",
            "Epoch 186/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2638.9751 - mae: 2638.9751 - mse: 30794838.0000 - val_loss: 2507.1206 - val_mae: 2507.1206 - val_mse: 28765638.0000\n",
            "Epoch 187/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2593.4587 - mae: 2593.4587 - mse: 30202548.0000 - val_loss: 2843.6218 - val_mae: 2843.6218 - val_mse: 30363128.0000\n",
            "Epoch 188/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2611.8276 - mae: 2611.8276 - mse: 30892668.0000 - val_loss: 2488.8738 - val_mae: 2488.8738 - val_mse: 27940002.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 189/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2534.3784 - mae: 2534.3784 - mse: 30297328.0000 - val_loss: 3010.8242 - val_mae: 3010.8242 - val_mse: 31058408.0000\n",
            "Epoch 190/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2673.2837 - mae: 2673.2837 - mse: 31313178.0000 - val_loss: 2533.8142 - val_mae: 2533.8142 - val_mse: 28702026.0000\n",
            "Epoch 191/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2569.5281 - mae: 2569.5281 - mse: 30488198.0000 - val_loss: 2468.2148 - val_mae: 2468.2148 - val_mse: 28012064.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 192/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2586.1863 - mae: 2586.1863 - mse: 30545384.0000 - val_loss: 2542.1426 - val_mae: 2542.1426 - val_mse: 28857772.0000\n",
            "Epoch 193/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2566.1831 - mae: 2566.1831 - mse: 30758818.0000 - val_loss: 2421.5867 - val_mae: 2421.5867 - val_mse: 28259400.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 194/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2519.1401 - mae: 2519.1401 - mse: 29827588.0000 - val_loss: 2705.4827 - val_mae: 2705.4827 - val_mse: 29226594.0000\n",
            "Epoch 195/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2551.7803 - mae: 2551.7803 - mse: 29878502.0000 - val_loss: 2497.7495 - val_mae: 2497.7495 - val_mse: 27479198.0000\n",
            "Epoch 196/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2501.5688 - mae: 2501.5688 - mse: 29715356.0000 - val_loss: 2671.8528 - val_mae: 2671.8528 - val_mse: 28882104.0000\n",
            "Epoch 197/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2584.9375 - mae: 2584.9375 - mse: 30218950.0000 - val_loss: 2547.3945 - val_mae: 2547.3945 - val_mse: 27658074.0000\n",
            "Epoch 198/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2525.2144 - mae: 2525.2144 - mse: 29453236.0000 - val_loss: 2350.3540 - val_mae: 2350.3540 - val_mse: 27722766.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 199/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2533.2708 - mae: 2533.2708 - mse: 29203250.0000 - val_loss: 2387.9675 - val_mae: 2387.9675 - val_mse: 27194780.0000\n",
            "Epoch 200/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2486.3547 - mae: 2486.3547 - mse: 29487588.0000 - val_loss: 2545.9819 - val_mae: 2545.9819 - val_mse: 28154612.0000\n",
            "Epoch 201/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2500.3777 - mae: 2500.3777 - mse: 29321922.0000 - val_loss: 2680.6780 - val_mae: 2680.6780 - val_mse: 27864440.0000\n",
            "Epoch 202/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2569.7769 - mae: 2569.7769 - mse: 29947236.0000 - val_loss: 2819.7119 - val_mae: 2819.7119 - val_mse: 29499832.0000\n",
            "Epoch 203/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2466.3972 - mae: 2466.3972 - mse: 29063244.0000 - val_loss: 2559.9827 - val_mae: 2559.9827 - val_mse: 28697730.0000\n",
            "Epoch 204/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2541.3511 - mae: 2541.3511 - mse: 29340724.0000 - val_loss: 2346.3269 - val_mae: 2346.3269 - val_mse: 27152986.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 205/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2504.9465 - mae: 2504.9465 - mse: 29125170.0000 - val_loss: 2508.2249 - val_mae: 2508.2249 - val_mse: 27985042.0000\n",
            "Epoch 206/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2482.4058 - mae: 2482.4058 - mse: 28666674.0000 - val_loss: 2613.4924 - val_mae: 2613.4924 - val_mse: 26892560.0000\n",
            "Epoch 207/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2473.5679 - mae: 2473.5679 - mse: 28151798.0000 - val_loss: 3055.9036 - val_mae: 3055.9036 - val_mse: 30218716.0000\n",
            "Epoch 208/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2512.2703 - mae: 2512.2703 - mse: 29421992.0000 - val_loss: 2477.8408 - val_mae: 2477.8408 - val_mse: 27184820.0000\n",
            "Epoch 209/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2453.2920 - mae: 2453.2920 - mse: 28667016.0000 - val_loss: 2473.5684 - val_mae: 2473.5684 - val_mse: 26699508.0000\n",
            "Epoch 210/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2485.7942 - mae: 2485.7942 - mse: 29559312.0000 - val_loss: 2589.4390 - val_mae: 2589.4390 - val_mse: 27208302.0000\n",
            "Epoch 211/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2466.5442 - mae: 2466.5442 - mse: 28646152.0000 - val_loss: 2874.6489 - val_mae: 2874.6489 - val_mse: 30149304.0000\n",
            "Epoch 212/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2427.1243 - mae: 2427.1243 - mse: 28012748.0000 - val_loss: 2670.6340 - val_mae: 2670.6340 - val_mse: 28422970.0000\n",
            "Epoch 213/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2441.3552 - mae: 2441.3552 - mse: 27959586.0000 - val_loss: 2663.6038 - val_mae: 2663.6038 - val_mse: 27460124.0000\n",
            "Epoch 214/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2456.4734 - mae: 2456.4734 - mse: 28663186.0000 - val_loss: 3000.4377 - val_mae: 3000.4377 - val_mse: 30423696.0000\n",
            "Epoch 215/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2413.7119 - mae: 2413.7119 - mse: 28378158.0000 - val_loss: 2399.1240 - val_mae: 2399.1240 - val_mse: 26764658.0000\n",
            "Epoch 216/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2436.2385 - mae: 2436.2385 - mse: 28057882.0000 - val_loss: 2295.5857 - val_mae: 2295.5857 - val_mse: 26648648.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 217/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2441.2659 - mae: 2441.2659 - mse: 28329416.0000 - val_loss: 2666.2102 - val_mae: 2666.2102 - val_mse: 28106184.0000\n",
            "Epoch 218/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2447.5981 - mae: 2447.5981 - mse: 28015838.0000 - val_loss: 2626.5725 - val_mae: 2626.5725 - val_mse: 28094676.0000\n",
            "Epoch 219/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2394.4529 - mae: 2394.4529 - mse: 28009098.0000 - val_loss: 3046.1455 - val_mae: 3046.1455 - val_mse: 29365078.0000\n",
            "Epoch 220/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2471.2629 - mae: 2471.2629 - mse: 28234568.0000 - val_loss: 2443.9194 - val_mae: 2443.9194 - val_mse: 26082096.0000\n",
            "Epoch 221/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2393.9221 - mae: 2393.9221 - mse: 27789430.0000 - val_loss: 2387.5728 - val_mae: 2387.5728 - val_mse: 25734106.0000\n",
            "Epoch 222/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2379.3921 - mae: 2379.3921 - mse: 27682296.0000 - val_loss: 2659.6765 - val_mae: 2659.6765 - val_mse: 28962362.0000\n",
            "Epoch 223/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2370.5601 - mae: 2370.5601 - mse: 27334910.0000 - val_loss: 2388.7056 - val_mae: 2388.7056 - val_mse: 27412942.0000\n",
            "Epoch 224/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2373.2664 - mae: 2373.2664 - mse: 27253624.0000 - val_loss: 2217.2576 - val_mae: 2217.2576 - val_mse: 25778020.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 225/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2438.6438 - mae: 2438.6438 - mse: 28281650.0000 - val_loss: 2737.0183 - val_mae: 2737.0183 - val_mse: 27205746.0000\n",
            "Epoch 226/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2431.8274 - mae: 2431.8274 - mse: 27926202.0000 - val_loss: 2385.3206 - val_mae: 2385.3206 - val_mse: 26036710.0000\n",
            "Epoch 227/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2401.5920 - mae: 2401.5920 - mse: 27403670.0000 - val_loss: 2189.4863 - val_mae: 2189.4863 - val_mse: 25350034.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 228/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2341.0771 - mae: 2341.0771 - mse: 27551878.0000 - val_loss: 2218.6208 - val_mae: 2218.6208 - val_mse: 25592896.0000\n",
            "Epoch 229/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2351.8689 - mae: 2351.8689 - mse: 27248896.0000 - val_loss: 2749.3159 - val_mae: 2749.3159 - val_mse: 28583596.0000\n",
            "Epoch 230/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2386.6611 - mae: 2386.6611 - mse: 27191774.0000 - val_loss: 2468.1833 - val_mae: 2468.1833 - val_mse: 26576080.0000\n",
            "Epoch 231/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2295.1091 - mae: 2295.1091 - mse: 26538552.0000 - val_loss: 2522.1602 - val_mae: 2522.1602 - val_mse: 26761134.0000\n",
            "Epoch 232/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2368.0420 - mae: 2368.0420 - mse: 27021166.0000 - val_loss: 2182.5259 - val_mae: 2182.5259 - val_mse: 24798432.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 233/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2358.4453 - mae: 2358.4453 - mse: 26917828.0000 - val_loss: 2372.8198 - val_mae: 2372.8198 - val_mse: 25285744.0000\n",
            "Epoch 234/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2308.6575 - mae: 2308.6575 - mse: 26280084.0000 - val_loss: 2277.6851 - val_mae: 2277.6851 - val_mse: 24899644.0000\n",
            "Epoch 235/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2351.7817 - mae: 2351.7817 - mse: 26817336.0000 - val_loss: 2555.2959 - val_mae: 2555.2959 - val_mse: 26528968.0000\n",
            "Epoch 236/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2313.7639 - mae: 2313.7639 - mse: 26343926.0000 - val_loss: 2651.4390 - val_mae: 2651.4390 - val_mse: 27496644.0000\n",
            "Epoch 237/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2293.0430 - mae: 2293.0430 - mse: 25771658.0000 - val_loss: 2173.6514 - val_mae: 2173.6514 - val_mse: 24300924.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 238/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2396.2258 - mae: 2396.2258 - mse: 27598654.0000 - val_loss: 2176.4907 - val_mae: 2176.4907 - val_mse: 24118478.0000\n",
            "Epoch 239/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2291.5750 - mae: 2291.5750 - mse: 26323464.0000 - val_loss: 2990.2678 - val_mae: 2990.2678 - val_mse: 27844390.0000\n",
            "Epoch 240/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2275.6074 - mae: 2275.6074 - mse: 25806880.0000 - val_loss: 2244.8000 - val_mae: 2244.8000 - val_mse: 25127548.0000\n",
            "Epoch 241/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2295.7361 - mae: 2295.7361 - mse: 26162202.0000 - val_loss: 2652.7192 - val_mae: 2652.7192 - val_mse: 26921716.0000\n",
            "Epoch 242/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2279.3625 - mae: 2279.3625 - mse: 26069984.0000 - val_loss: 2117.0264 - val_mae: 2117.0264 - val_mse: 24317110.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 243/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2301.3069 - mae: 2301.3069 - mse: 25787832.0000 - val_loss: 2314.3254 - val_mae: 2314.3254 - val_mse: 25208232.0000\n",
            "Epoch 244/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2273.8188 - mae: 2273.8188 - mse: 25562834.0000 - val_loss: 2310.8398 - val_mae: 2310.8398 - val_mse: 24844786.0000\n",
            "Epoch 245/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2254.7571 - mae: 2254.7571 - mse: 25118996.0000 - val_loss: 2305.4771 - val_mae: 2305.4771 - val_mse: 25161976.0000\n",
            "Epoch 246/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2294.8696 - mae: 2294.8696 - mse: 25756600.0000 - val_loss: 2361.3335 - val_mae: 2361.3335 - val_mse: 25365358.0000\n",
            "Epoch 247/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2251.6865 - mae: 2251.6865 - mse: 25807702.0000 - val_loss: 2556.4751 - val_mae: 2556.4751 - val_mse: 26246278.0000\n",
            "Epoch 248/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2308.4373 - mae: 2308.4373 - mse: 26218932.0000 - val_loss: 2122.9417 - val_mae: 2122.9417 - val_mse: 23326232.0000\n",
            "Epoch 249/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2239.7124 - mae: 2239.7124 - mse: 25171044.0000 - val_loss: 2343.5615 - val_mae: 2343.5615 - val_mse: 22795828.0000\n",
            "Epoch 250/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2217.1538 - mae: 2217.1538 - mse: 24709392.0000 - val_loss: 2095.6528 - val_mae: 2095.6528 - val_mse: 23949462.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 251/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2248.9084 - mae: 2248.9084 - mse: 25259064.0000 - val_loss: 2259.9756 - val_mae: 2259.9756 - val_mse: 24494510.0000\n",
            "Epoch 252/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2219.1802 - mae: 2219.1802 - mse: 24739778.0000 - val_loss: 2197.3335 - val_mae: 2197.3335 - val_mse: 22953650.0000\n",
            "Epoch 253/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2279.4705 - mae: 2279.4705 - mse: 25603544.0000 - val_loss: 2231.3586 - val_mae: 2231.3586 - val_mse: 24279934.0000\n",
            "Epoch 254/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2197.4573 - mae: 2197.4573 - mse: 25153186.0000 - val_loss: 2138.7468 - val_mae: 2138.7468 - val_mse: 23694556.0000\n",
            "Epoch 255/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2211.0444 - mae: 2211.0444 - mse: 24376882.0000 - val_loss: 2122.9990 - val_mae: 2122.9990 - val_mse: 23724426.0000\n",
            "Epoch 256/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2196.1643 - mae: 2196.1643 - mse: 24510364.0000 - val_loss: 2551.4602 - val_mae: 2551.4602 - val_mse: 26322844.0000\n",
            "Epoch 257/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2238.2341 - mae: 2238.2341 - mse: 24636962.0000 - val_loss: 2340.3384 - val_mae: 2340.3384 - val_mse: 24600154.0000\n",
            "Epoch 258/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2196.6074 - mae: 2196.6074 - mse: 24578502.0000 - val_loss: 2573.5154 - val_mae: 2573.5154 - val_mse: 26443924.0000\n",
            "Epoch 259/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2226.4565 - mae: 2226.4565 - mse: 24022638.0000 - val_loss: 2084.2258 - val_mae: 2084.2258 - val_mse: 23374844.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 260/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2221.8723 - mae: 2221.8723 - mse: 24770036.0000 - val_loss: 2112.6680 - val_mae: 2112.6680 - val_mse: 22838026.0000\n",
            "Epoch 261/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2193.9775 - mae: 2193.9775 - mse: 23913732.0000 - val_loss: 2111.0952 - val_mae: 2111.0952 - val_mse: 23555528.0000\n",
            "Epoch 262/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2201.7725 - mae: 2201.7725 - mse: 24101204.0000 - val_loss: 2119.0259 - val_mae: 2119.0259 - val_mse: 22385168.0000\n",
            "Epoch 263/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2086.1772 - mae: 2086.1772 - mse: 23500244.0000 - val_loss: 2586.8096 - val_mae: 2586.8096 - val_mse: 26257758.0000\n",
            "Epoch 264/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2209.6460 - mae: 2209.6460 - mse: 24896024.0000 - val_loss: 2454.7847 - val_mae: 2454.7847 - val_mse: 22077938.0000\n",
            "Epoch 265/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2157.2996 - mae: 2157.2996 - mse: 24164408.0000 - val_loss: 3553.9404 - val_mae: 3553.9404 - val_mse: 31235922.0000\n",
            "Epoch 266/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2172.9968 - mae: 2172.9968 - mse: 23839242.0000 - val_loss: 2102.2681 - val_mae: 2102.2681 - val_mse: 23324994.0000\n",
            "Epoch 267/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2205.0627 - mae: 2205.0627 - mse: 24705074.0000 - val_loss: 2413.5085 - val_mae: 2413.5085 - val_mse: 24501250.0000\n",
            "Epoch 268/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2124.6189 - mae: 2124.6189 - mse: 24261080.0000 - val_loss: 2586.3284 - val_mae: 2586.3284 - val_mse: 26338508.0000\n",
            "Epoch 269/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2175.6448 - mae: 2175.6448 - mse: 23817068.0000 - val_loss: 2384.3076 - val_mae: 2384.3076 - val_mse: 23243360.0000\n",
            "Epoch 270/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2184.0139 - mae: 2184.0139 - mse: 23990316.0000 - val_loss: 2087.3896 - val_mae: 2087.3896 - val_mse: 22054856.0000\n",
            "Epoch 271/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2127.7322 - mae: 2127.7322 - mse: 23872318.0000 - val_loss: 2041.6279 - val_mae: 2041.6279 - val_mse: 22455804.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 272/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2199.9885 - mae: 2199.9885 - mse: 24524096.0000 - val_loss: 1978.4456 - val_mae: 1978.4456 - val_mse: 22381046.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 273/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2128.1995 - mae: 2128.1995 - mse: 23709522.0000 - val_loss: 3190.3879 - val_mae: 3190.3879 - val_mse: 27165602.0000\n",
            "Epoch 274/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2175.3115 - mae: 2175.3115 - mse: 23514102.0000 - val_loss: 2454.4600 - val_mae: 2454.4600 - val_mse: 22896576.0000\n",
            "Epoch 275/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2131.0935 - mae: 2131.0935 - mse: 23270122.0000 - val_loss: 2366.7844 - val_mae: 2366.7844 - val_mse: 24547328.0000\n",
            "Epoch 276/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2145.0857 - mae: 2145.0857 - mse: 23480592.0000 - val_loss: 2010.4323 - val_mae: 2010.4323 - val_mse: 22396280.0000\n",
            "Epoch 277/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2122.3560 - mae: 2122.3560 - mse: 23188814.0000 - val_loss: 2097.0979 - val_mae: 2097.0979 - val_mse: 22922508.0000\n",
            "Epoch 278/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2181.3992 - mae: 2181.3992 - mse: 23617436.0000 - val_loss: 2151.6270 - val_mae: 2151.6270 - val_mse: 21437530.0000\n",
            "Epoch 279/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2077.3953 - mae: 2077.3953 - mse: 23104582.0000 - val_loss: 2563.6548 - val_mae: 2563.6548 - val_mse: 25797388.0000\n",
            "Epoch 280/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2168.5842 - mae: 2168.5842 - mse: 23818114.0000 - val_loss: 2009.4556 - val_mae: 2009.4556 - val_mse: 21768742.0000\n",
            "Epoch 281/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2090.8188 - mae: 2090.8188 - mse: 23089496.0000 - val_loss: 1944.4760 - val_mae: 1944.4760 - val_mse: 22278828.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 282/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2083.5234 - mae: 2083.5234 - mse: 22848192.0000 - val_loss: 2225.5918 - val_mae: 2225.5918 - val_mse: 21998386.0000\n",
            "Epoch 283/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2083.1213 - mae: 2083.1213 - mse: 22454250.0000 - val_loss: 2235.8530 - val_mae: 2235.8530 - val_mse: 23271102.0000\n",
            "Epoch 284/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2148.0713 - mae: 2148.0713 - mse: 23749314.0000 - val_loss: 2243.8599 - val_mae: 2243.8599 - val_mse: 23504604.0000\n",
            "Epoch 285/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2054.6372 - mae: 2054.6372 - mse: 22607516.0000 - val_loss: 2038.2512 - val_mae: 2038.2512 - val_mse: 21331676.0000\n",
            "Epoch 286/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2134.4282 - mae: 2134.4282 - mse: 23221166.0000 - val_loss: 2029.0464 - val_mae: 2029.0464 - val_mse: 22384554.0000\n",
            "Epoch 287/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2055.5359 - mae: 2055.5359 - mse: 22616398.0000 - val_loss: 2312.0876 - val_mae: 2312.0876 - val_mse: 24004488.0000\n",
            "Epoch 288/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2122.9932 - mae: 2122.9932 - mse: 23101708.0000 - val_loss: 2309.2412 - val_mae: 2309.2412 - val_mse: 24686682.0000\n",
            "Epoch 289/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2049.3633 - mae: 2049.3633 - mse: 22446820.0000 - val_loss: 2795.1169 - val_mae: 2795.1169 - val_mse: 29938732.0000\n",
            "Epoch 290/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2045.1257 - mae: 2045.1257 - mse: 22855980.0000 - val_loss: 1967.4355 - val_mae: 1967.4355 - val_mse: 22181548.0000\n",
            "Epoch 291/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2036.5802 - mae: 2036.5802 - mse: 22237292.0000 - val_loss: 2007.1753 - val_mae: 2007.1753 - val_mse: 22209722.0000\n",
            "Epoch 292/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2073.2490 - mae: 2073.2490 - mse: 23006866.0000 - val_loss: 2392.4077 - val_mae: 2392.4077 - val_mse: 22023238.0000\n",
            "Epoch 293/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2081.4717 - mae: 2081.4717 - mse: 22742444.0000 - val_loss: 2505.6160 - val_mae: 2505.6160 - val_mse: 25843588.0000\n",
            "Epoch 294/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2075.0593 - mae: 2075.0593 - mse: 22160210.0000 - val_loss: 2253.0422 - val_mae: 2253.0422 - val_mse: 20713800.0000\n",
            "Epoch 295/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2039.1959 - mae: 2039.1959 - mse: 21973696.0000 - val_loss: 2076.9038 - val_mae: 2076.9038 - val_mse: 22554772.0000\n",
            "Epoch 296/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2110.8401 - mae: 2110.8401 - mse: 23076352.0000 - val_loss: 2025.2916 - val_mae: 2025.2916 - val_mse: 20529834.0000\n",
            "Epoch 297/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2100.5232 - mae: 2100.5232 - mse: 23158770.0000 - val_loss: 1907.2004 - val_mae: 1907.2004 - val_mse: 21311670.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 298/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1967.5719 - mae: 1967.5719 - mse: 22263382.0000 - val_loss: 2025.1125 - val_mae: 2025.1125 - val_mse: 22544440.0000\n",
            "Epoch 299/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2074.9678 - mae: 2074.9678 - mse: 22846622.0000 - val_loss: 2042.9667 - val_mae: 2042.9667 - val_mse: 22320164.0000\n",
            "Epoch 300/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2025.4760 - mae: 2025.4760 - mse: 22008398.0000 - val_loss: 2276.0667 - val_mae: 2276.0667 - val_mse: 20823578.0000\n",
            "Epoch 301/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2018.3802 - mae: 2018.3802 - mse: 22163312.0000 - val_loss: 1834.7977 - val_mae: 1834.7977 - val_mse: 21088818.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 302/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1989.0374 - mae: 1989.0374 - mse: 22181762.0000 - val_loss: 2403.8306 - val_mae: 2403.8306 - val_mse: 20881504.0000\n",
            "Epoch 303/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2030.0762 - mae: 2030.0762 - mse: 22367192.0000 - val_loss: 2740.9050 - val_mae: 2740.9050 - val_mse: 23628216.0000\n",
            "Epoch 304/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2058.7446 - mae: 2058.7446 - mse: 21881364.0000 - val_loss: 1917.0848 - val_mae: 1917.0848 - val_mse: 21318856.0000\n",
            "Epoch 305/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1993.4872 - mae: 1993.4872 - mse: 21972922.0000 - val_loss: 2284.0437 - val_mae: 2284.0437 - val_mse: 23349480.0000\n",
            "Epoch 306/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2031.1548 - mae: 2031.1548 - mse: 21865508.0000 - val_loss: 1827.1025 - val_mae: 1827.1025 - val_mse: 20781008.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 307/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2012.3303 - mae: 2012.3303 - mse: 22271394.0000 - val_loss: 1966.2847 - val_mae: 1966.2847 - val_mse: 20490212.0000\n",
            "Epoch 308/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2023.5909 - mae: 2023.5909 - mse: 22381412.0000 - val_loss: 1866.5581 - val_mae: 1866.5581 - val_mse: 20529226.0000\n",
            "Epoch 309/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1964.5374 - mae: 1964.5374 - mse: 22055898.0000 - val_loss: 2043.0166 - val_mae: 2043.0166 - val_mse: 20145478.0000\n",
            "Epoch 310/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2008.3485 - mae: 2008.3485 - mse: 22024280.0000 - val_loss: 2510.0671 - val_mae: 2510.0671 - val_mse: 26237310.0000\n",
            "Epoch 311/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1988.3695 - mae: 1988.3695 - mse: 21896374.0000 - val_loss: 1988.8035 - val_mae: 1988.8035 - val_mse: 21308158.0000\n",
            "Epoch 312/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1996.9242 - mae: 1996.9242 - mse: 21524282.0000 - val_loss: 1928.5278 - val_mae: 1928.5278 - val_mse: 21614686.0000\n",
            "Epoch 313/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1983.5615 - mae: 1983.5615 - mse: 22353254.0000 - val_loss: 1949.8363 - val_mae: 1949.8363 - val_mse: 20895368.0000\n",
            "Epoch 314/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2028.3505 - mae: 2028.3505 - mse: 22325554.0000 - val_loss: 1867.4657 - val_mae: 1867.4657 - val_mse: 20788880.0000\n",
            "Epoch 315/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1945.7885 - mae: 1945.7885 - mse: 21500924.0000 - val_loss: 2212.2019 - val_mae: 2212.2019 - val_mse: 22401206.0000\n",
            "Epoch 316/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2034.3026 - mae: 2034.3026 - mse: 22074316.0000 - val_loss: 1968.3301 - val_mae: 1968.3301 - val_mse: 20176522.0000\n",
            "Epoch 317/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1980.0179 - mae: 1980.0179 - mse: 22050678.0000 - val_loss: 1822.4362 - val_mae: 1822.4362 - val_mse: 20567178.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 318/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2018.5500 - mae: 2018.5500 - mse: 22343884.0000 - val_loss: 2204.7419 - val_mae: 2204.7419 - val_mse: 23926052.0000\n",
            "Epoch 319/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2004.5015 - mae: 2004.5015 - mse: 21597298.0000 - val_loss: 1878.2697 - val_mae: 1878.2697 - val_mse: 21190392.0000\n",
            "Epoch 320/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1998.8234 - mae: 1998.8234 - mse: 21946434.0000 - val_loss: 2082.7876 - val_mae: 2082.7876 - val_mse: 22327612.0000\n",
            "Epoch 321/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1947.6133 - mae: 1947.6133 - mse: 21602376.0000 - val_loss: 2098.3364 - val_mae: 2098.3364 - val_mse: 20694040.0000\n",
            "Epoch 322/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2003.9050 - mae: 2003.9053 - mse: 21922198.0000 - val_loss: 2000.4919 - val_mae: 2000.4919 - val_mse: 19894306.0000\n",
            "Epoch 323/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1948.8306 - mae: 1948.8306 - mse: 21629390.0000 - val_loss: 1836.9213 - val_mae: 1836.9211 - val_mse: 20056256.0000\n",
            "Epoch 324/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1998.7074 - mae: 1998.7074 - mse: 22126710.0000 - val_loss: 3097.8359 - val_mae: 3097.8359 - val_mse: 26440148.0000\n",
            "Epoch 325/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1985.5409 - mae: 1985.5409 - mse: 21939982.0000 - val_loss: 1980.1766 - val_mae: 1980.1766 - val_mse: 19628278.0000\n",
            "Epoch 326/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1976.7543 - mae: 1976.7543 - mse: 21980992.0000 - val_loss: 1841.0631 - val_mae: 1841.0631 - val_mse: 20064790.0000\n",
            "Epoch 327/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1950.4463 - mae: 1950.4463 - mse: 21472802.0000 - val_loss: 1890.3379 - val_mae: 1890.3379 - val_mse: 21051360.0000\n",
            "Epoch 328/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1930.8325 - mae: 1930.8325 - mse: 21146478.0000 - val_loss: 2168.6245 - val_mae: 2168.6245 - val_mse: 22743038.0000\n",
            "Epoch 329/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1959.8534 - mae: 1959.8534 - mse: 21418732.0000 - val_loss: 2541.1895 - val_mae: 2541.1895 - val_mse: 21191146.0000\n",
            "Epoch 330/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1912.9324 - mae: 1912.9324 - mse: 21322462.0000 - val_loss: 1846.3058 - val_mae: 1846.3058 - val_mse: 20817870.0000\n",
            "Epoch 331/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1989.2144 - mae: 1989.2144 - mse: 21782760.0000 - val_loss: 1992.1976 - val_mae: 1992.1976 - val_mse: 21177884.0000\n",
            "Epoch 332/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1944.1570 - mae: 1944.1570 - mse: 21553944.0000 - val_loss: 2299.5110 - val_mae: 2299.5110 - val_mse: 21214564.0000\n",
            "Epoch 333/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1989.1476 - mae: 1989.1476 - mse: 22026602.0000 - val_loss: 2073.7544 - val_mae: 2073.7544 - val_mse: 19872538.0000\n",
            "Epoch 334/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1931.1495 - mae: 1931.1495 - mse: 21563876.0000 - val_loss: 2805.8533 - val_mae: 2805.8533 - val_mse: 30513092.0000\n",
            "Epoch 335/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1979.0609 - mae: 1979.0609 - mse: 21742420.0000 - val_loss: 2211.1465 - val_mae: 2211.1465 - val_mse: 21837738.0000\n",
            "Epoch 336/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1933.7664 - mae: 1933.7664 - mse: 21444204.0000 - val_loss: 2769.9065 - val_mae: 2769.9065 - val_mse: 23136978.0000\n",
            "Epoch 337/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1959.8324 - mae: 1959.8324 - mse: 21738070.0000 - val_loss: 2032.2079 - val_mae: 2032.2079 - val_mse: 19661880.0000\n",
            "Epoch 338/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1996.3655 - mae: 1996.3655 - mse: 22140988.0000 - val_loss: 1994.5520 - val_mae: 1994.5520 - val_mse: 22970736.0000\n",
            "Epoch 339/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1896.8147 - mae: 1896.8147 - mse: 21331284.0000 - val_loss: 1891.5447 - val_mae: 1891.5447 - val_mse: 21473166.0000\n",
            "Epoch 340/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1941.7932 - mae: 1941.7932 - mse: 21405318.0000 - val_loss: 2696.4287 - val_mae: 2696.4287 - val_mse: 28313552.0000\n",
            "Epoch 341/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1962.3312 - mae: 1962.3312 - mse: 22142164.0000 - val_loss: 1974.8335 - val_mae: 1974.8335 - val_mse: 20080326.0000\n",
            "Epoch 342/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1897.3353 - mae: 1897.3353 - mse: 21063836.0000 - val_loss: 2046.5389 - val_mae: 2046.5389 - val_mse: 19509206.0000\n",
            "Epoch 343/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1947.8362 - mae: 1947.8362 - mse: 21469418.0000 - val_loss: 1821.5542 - val_mae: 1821.5542 - val_mse: 20815774.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 344/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1931.6118 - mae: 1931.6118 - mse: 21394002.0000 - val_loss: 1940.0188 - val_mae: 1940.0188 - val_mse: 21443668.0000\n",
            "Epoch 345/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1913.2513 - mae: 1913.2513 - mse: 21046116.0000 - val_loss: 1851.8090 - val_mae: 1851.8090 - val_mse: 20447718.0000\n",
            "Epoch 346/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1981.9817 - mae: 1981.9817 - mse: 21902544.0000 - val_loss: 2267.5344 - val_mae: 2267.5344 - val_mse: 20715810.0000\n",
            "Epoch 347/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2023.3082 - mae: 2023.3082 - mse: 22260808.0000 - val_loss: 1830.1028 - val_mae: 1830.1028 - val_mse: 20769150.0000\n",
            "Epoch 348/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1861.8771 - mae: 1861.8771 - mse: 21057268.0000 - val_loss: 1754.1606 - val_mae: 1754.1606 - val_mse: 19888290.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 349/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1948.5415 - mae: 1948.5415 - mse: 21365630.0000 - val_loss: 1830.7357 - val_mae: 1830.7357 - val_mse: 20105958.0000\n",
            "Epoch 350/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1953.2375 - mae: 1953.2375 - mse: 21990604.0000 - val_loss: 1940.6840 - val_mae: 1940.6840 - val_mse: 19327100.0000\n",
            "Epoch 351/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1891.7596 - mae: 1891.7596 - mse: 21200462.0000 - val_loss: 2063.9495 - val_mae: 2063.9495 - val_mse: 19725798.0000\n",
            "Epoch 352/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1970.2545 - mae: 1970.2545 - mse: 21353534.0000 - val_loss: 1889.3291 - val_mae: 1889.3291 - val_mse: 19483862.0000\n",
            "Epoch 353/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1936.5648 - mae: 1936.5648 - mse: 21395354.0000 - val_loss: 2022.5781 - val_mae: 2022.5781 - val_mse: 23080288.0000\n",
            "Epoch 354/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1954.0392 - mae: 1954.0392 - mse: 21502036.0000 - val_loss: 2478.4033 - val_mae: 2478.4033 - val_mse: 25183634.0000\n",
            "Epoch 355/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1929.7670 - mae: 1929.7670 - mse: 21328224.0000 - val_loss: 2007.0530 - val_mae: 2007.0530 - val_mse: 22403482.0000\n",
            "Epoch 356/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1858.5402 - mae: 1858.5402 - mse: 20603304.0000 - val_loss: 2098.6355 - val_mae: 2098.6355 - val_mse: 22640590.0000\n",
            "Epoch 357/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1902.5103 - mae: 1902.5103 - mse: 21608900.0000 - val_loss: 2356.8232 - val_mae: 2356.8232 - val_mse: 24674280.0000\n",
            "Epoch 358/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1920.3641 - mae: 1920.3641 - mse: 21304004.0000 - val_loss: 2213.6990 - val_mae: 2213.6987 - val_mse: 19421148.0000\n",
            "Epoch 359/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1923.1205 - mae: 1923.1205 - mse: 21638486.0000 - val_loss: 1770.5006 - val_mae: 1770.5006 - val_mse: 19984392.0000\n",
            "Epoch 360/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1918.0172 - mae: 1918.0172 - mse: 20973000.0000 - val_loss: 2348.2874 - val_mae: 2348.2874 - val_mse: 22229036.0000\n",
            "Epoch 361/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1895.6342 - mae: 1895.6342 - mse: 20933694.0000 - val_loss: 1899.2147 - val_mae: 1899.2147 - val_mse: 19453732.0000\n",
            "Epoch 362/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1924.8856 - mae: 1924.8856 - mse: 21374440.0000 - val_loss: 2014.7328 - val_mae: 2014.7328 - val_mse: 19556498.0000\n",
            "Epoch 363/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1863.8075 - mae: 1863.8075 - mse: 21053304.0000 - val_loss: 1834.3335 - val_mae: 1834.3335 - val_mse: 19676002.0000\n",
            "Epoch 364/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1907.1973 - mae: 1907.1973 - mse: 21301640.0000 - val_loss: 1741.0798 - val_mae: 1741.0798 - val_mse: 19602542.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 365/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1881.2731 - mae: 1881.2731 - mse: 20848894.0000 - val_loss: 1936.8354 - val_mae: 1936.8354 - val_mse: 20505694.0000\n",
            "Epoch 366/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1883.3386 - mae: 1883.3386 - mse: 21427466.0000 - val_loss: 2007.6858 - val_mae: 2007.6858 - val_mse: 22006922.0000\n",
            "Epoch 367/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1890.7267 - mae: 1890.7267 - mse: 20838586.0000 - val_loss: 2269.0735 - val_mae: 2269.0735 - val_mse: 21012398.0000\n",
            "Epoch 368/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1893.2357 - mae: 1893.2357 - mse: 20722288.0000 - val_loss: 2284.8167 - val_mae: 2284.8167 - val_mse: 24012474.0000\n",
            "Epoch 369/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1888.9817 - mae: 1888.9817 - mse: 20961812.0000 - val_loss: 2111.8381 - val_mae: 2111.8381 - val_mse: 22557930.0000\n",
            "Epoch 370/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1912.8759 - mae: 1912.8759 - mse: 21359288.0000 - val_loss: 1914.5707 - val_mae: 1914.5707 - val_mse: 19008642.0000\n",
            "Epoch 371/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1876.9719 - mae: 1876.9719 - mse: 20454668.0000 - val_loss: 1805.9711 - val_mae: 1805.9711 - val_mse: 21272580.0000\n",
            "Epoch 372/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1888.4764 - mae: 1888.4764 - mse: 21383468.0000 - val_loss: 2001.4293 - val_mae: 2001.4293 - val_mse: 19075290.0000\n",
            "Epoch 373/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1870.7196 - mae: 1870.7196 - mse: 20669640.0000 - val_loss: 1872.9806 - val_mae: 1872.9806 - val_mse: 21093876.0000\n",
            "Epoch 374/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1905.1605 - mae: 1905.1605 - mse: 21324628.0000 - val_loss: 2068.9343 - val_mae: 2068.9343 - val_mse: 22599164.0000\n",
            "Epoch 375/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1851.3357 - mae: 1851.3357 - mse: 20827010.0000 - val_loss: 1827.9805 - val_mae: 1827.9805 - val_mse: 19391678.0000\n",
            "Epoch 376/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1862.9581 - mae: 1862.9581 - mse: 20937160.0000 - val_loss: 1872.2729 - val_mae: 1872.2729 - val_mse: 21187970.0000\n",
            "Epoch 377/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1897.1841 - mae: 1897.1841 - mse: 21151562.0000 - val_loss: 1708.4697 - val_mae: 1708.4697 - val_mse: 19731630.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 378/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1884.9473 - mae: 1884.9473 - mse: 21132944.0000 - val_loss: 1707.0140 - val_mae: 1707.0140 - val_mse: 19922662.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 379/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1893.5029 - mae: 1893.5029 - mse: 21170026.0000 - val_loss: 1864.3661 - val_mae: 1864.3661 - val_mse: 19065140.0000\n",
            "Epoch 380/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1873.8528 - mae: 1873.8528 - mse: 21207694.0000 - val_loss: 1898.0828 - val_mae: 1898.0828 - val_mse: 19164820.0000\n",
            "Epoch 381/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1829.1144 - mae: 1829.1144 - mse: 20078044.0000 - val_loss: 1926.8119 - val_mae: 1926.8119 - val_mse: 19740974.0000\n",
            "Epoch 382/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1934.2227 - mae: 1934.2227 - mse: 21710394.0000 - val_loss: 1861.8005 - val_mae: 1861.8005 - val_mse: 19929742.0000\n",
            "Epoch 383/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1899.2899 - mae: 1899.2899 - mse: 21476472.0000 - val_loss: 1721.4921 - val_mae: 1721.4921 - val_mse: 20305882.0000\n",
            "Epoch 384/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1808.6926 - mae: 1808.6926 - mse: 20341550.0000 - val_loss: 2269.2483 - val_mae: 2269.2483 - val_mse: 21049004.0000\n",
            "Epoch 385/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1896.9546 - mae: 1896.9546 - mse: 20933426.0000 - val_loss: 1945.3190 - val_mae: 1945.3190 - val_mse: 21397590.0000\n",
            "Epoch 386/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1873.4071 - mae: 1873.4071 - mse: 21174574.0000 - val_loss: 1954.5328 - val_mae: 1954.5328 - val_mse: 19489404.0000\n",
            "Epoch 387/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1835.5662 - mae: 1835.5662 - mse: 20552408.0000 - val_loss: 1791.9178 - val_mae: 1791.9178 - val_mse: 19808930.0000\n",
            "Epoch 388/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1848.0197 - mae: 1848.0197 - mse: 20413838.0000 - val_loss: 1714.8383 - val_mae: 1714.8383 - val_mse: 20255304.0000\n",
            "Epoch 389/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1931.8180 - mae: 1931.8180 - mse: 21410958.0000 - val_loss: 2008.7218 - val_mae: 2008.7218 - val_mse: 18924578.0000\n",
            "Epoch 390/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1885.3254 - mae: 1885.3254 - mse: 20896766.0000 - val_loss: 2063.8279 - val_mae: 2063.8279 - val_mse: 22670288.0000\n",
            "Epoch 391/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1831.8624 - mae: 1831.8624 - mse: 20589642.0000 - val_loss: 1843.8900 - val_mae: 1843.8900 - val_mse: 21382368.0000\n",
            "Epoch 392/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1861.9427 - mae: 1861.9427 - mse: 20549732.0000 - val_loss: 2561.1104 - val_mae: 2561.1104 - val_mse: 21242124.0000\n",
            "Epoch 393/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1824.1962 - mae: 1824.1962 - mse: 20431144.0000 - val_loss: 1774.3186 - val_mae: 1774.3186 - val_mse: 20286222.0000\n",
            "Epoch 394/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1822.8816 - mae: 1822.8816 - mse: 20479094.0000 - val_loss: 1913.5627 - val_mae: 1913.5627 - val_mse: 21223146.0000\n",
            "Epoch 395/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1834.2729 - mae: 1834.2729 - mse: 20702368.0000 - val_loss: 2378.5095 - val_mae: 2378.5095 - val_mse: 22987312.0000\n",
            "Epoch 396/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1902.1385 - mae: 1902.1385 - mse: 20869280.0000 - val_loss: 1661.0308 - val_mae: 1661.0308 - val_mse: 19805308.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 397/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1823.0848 - mae: 1823.0848 - mse: 20631940.0000 - val_loss: 2023.6512 - val_mae: 2023.6512 - val_mse: 21649396.0000\n",
            "Epoch 398/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1846.8527 - mae: 1846.8527 - mse: 20801508.0000 - val_loss: 1983.9202 - val_mae: 1983.9202 - val_mse: 19617042.0000\n",
            "Epoch 399/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1865.6233 - mae: 1865.6233 - mse: 20569682.0000 - val_loss: 1811.6519 - val_mae: 1811.6519 - val_mse: 21183058.0000\n",
            "Epoch 400/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1810.6685 - mae: 1810.6685 - mse: 20413700.0000 - val_loss: 1915.3007 - val_mae: 1915.3007 - val_mse: 22485160.0000\n",
            "Epoch 401/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1845.3082 - mae: 1845.3082 - mse: 20775618.0000 - val_loss: 2204.8152 - val_mae: 2204.8152 - val_mse: 22910302.0000\n",
            "Epoch 402/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1850.2440 - mae: 1850.2440 - mse: 20467522.0000 - val_loss: 2069.2727 - val_mae: 2069.2727 - val_mse: 19180186.0000\n",
            "Epoch 403/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1843.1770 - mae: 1843.1770 - mse: 20503390.0000 - val_loss: 1897.9132 - val_mae: 1897.9132 - val_mse: 18815514.0000\n",
            "Epoch 404/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1843.2953 - mae: 1843.2953 - mse: 20616066.0000 - val_loss: 1666.5371 - val_mae: 1666.5371 - val_mse: 19776982.0000\n",
            "Epoch 405/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1807.6914 - mae: 1807.6914 - mse: 20706544.0000 - val_loss: 2155.2422 - val_mae: 2155.2419 - val_mse: 19683860.0000\n",
            "Epoch 406/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1806.3652 - mae: 1806.3652 - mse: 20288672.0000 - val_loss: 1756.2037 - val_mae: 1756.2037 - val_mse: 21053770.0000\n",
            "Epoch 407/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1803.4919 - mae: 1803.4919 - mse: 20414526.0000 - val_loss: 2167.3608 - val_mae: 2167.3608 - val_mse: 19626872.0000\n",
            "Epoch 408/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1892.4998 - mae: 1892.4998 - mse: 21060564.0000 - val_loss: 2124.2698 - val_mae: 2124.2698 - val_mse: 20452672.0000\n",
            "Epoch 409/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1807.9854 - mae: 1807.9854 - mse: 20496506.0000 - val_loss: 2215.4768 - val_mae: 2215.4768 - val_mse: 25324896.0000\n",
            "Epoch 410/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1821.1877 - mae: 1821.1877 - mse: 20155104.0000 - val_loss: 2336.6113 - val_mae: 2336.6113 - val_mse: 21267760.0000\n",
            "Epoch 411/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1783.2681 - mae: 1783.2681 - mse: 20245860.0000 - val_loss: 1805.6346 - val_mae: 1805.6346 - val_mse: 19376556.0000\n",
            "Epoch 412/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1859.6199 - mae: 1859.6199 - mse: 20731370.0000 - val_loss: 1950.8088 - val_mae: 1950.8088 - val_mse: 19235884.0000\n",
            "Epoch 413/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1847.9370 - mae: 1847.9370 - mse: 20985628.0000 - val_loss: 1813.6958 - val_mae: 1813.6958 - val_mse: 21687040.0000\n",
            "Epoch 414/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1838.9115 - mae: 1838.9115 - mse: 20573844.0000 - val_loss: 1974.1271 - val_mae: 1974.1271 - val_mse: 19245996.0000\n",
            "Epoch 415/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1797.2046 - mae: 1797.2046 - mse: 20332420.0000 - val_loss: 1680.1858 - val_mae: 1680.1858 - val_mse: 19595784.0000\n",
            "Epoch 416/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1826.8698 - mae: 1826.8698 - mse: 20349496.0000 - val_loss: 1686.9956 - val_mae: 1686.9956 - val_mse: 19596554.0000\n",
            "Epoch 417/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1793.5435 - mae: 1793.5435 - mse: 20500126.0000 - val_loss: 2056.2283 - val_mae: 2056.2283 - val_mse: 19005960.0000\n",
            "Epoch 418/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1797.4114 - mae: 1797.4114 - mse: 20077984.0000 - val_loss: 1811.6022 - val_mae: 1811.6022 - val_mse: 19226422.0000\n",
            "Epoch 419/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1805.2103 - mae: 1805.2103 - mse: 20439200.0000 - val_loss: 1736.5148 - val_mae: 1736.5148 - val_mse: 19875738.0000\n",
            "Epoch 420/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1764.0649 - mae: 1764.0649 - mse: 19987930.0000 - val_loss: 2091.9143 - val_mae: 2091.9143 - val_mse: 19850576.0000\n",
            "Epoch 421/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1822.7954 - mae: 1822.7954 - mse: 20142738.0000 - val_loss: 2077.1182 - val_mae: 2077.1182 - val_mse: 19577570.0000\n",
            "Epoch 422/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1765.3771 - mae: 1765.3771 - mse: 20163446.0000 - val_loss: 2527.8894 - val_mae: 2527.8894 - val_mse: 22261446.0000\n",
            "Epoch 423/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1821.3254 - mae: 1821.3254 - mse: 20537970.0000 - val_loss: 2333.7202 - val_mae: 2333.7202 - val_mse: 24140280.0000\n",
            "Epoch 424/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1828.6743 - mae: 1828.6743 - mse: 20536004.0000 - val_loss: 1647.4415 - val_mae: 1647.4415 - val_mse: 19331140.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 425/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1879.4628 - mae: 1879.4628 - mse: 21317830.0000 - val_loss: 1911.3904 - val_mae: 1911.3904 - val_mse: 19108444.0000\n",
            "Epoch 426/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1780.3477 - mae: 1780.3477 - mse: 20210174.0000 - val_loss: 2678.7341 - val_mae: 2678.7341 - val_mse: 28611952.0000\n",
            "Epoch 427/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1791.2795 - mae: 1791.2795 - mse: 20133022.0000 - val_loss: 2410.2915 - val_mae: 2410.2915 - val_mse: 27761306.0000\n",
            "Epoch 428/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1784.2178 - mae: 1784.2178 - mse: 20422984.0000 - val_loss: 1693.7207 - val_mae: 1693.7207 - val_mse: 20356390.0000\n",
            "Epoch 429/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1857.7795 - mae: 1857.7795 - mse: 21072412.0000 - val_loss: 1871.2380 - val_mae: 1871.2380 - val_mse: 21537840.0000\n",
            "Epoch 430/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1807.0549 - mae: 1807.0549 - mse: 20239664.0000 - val_loss: 1836.8529 - val_mae: 1836.8529 - val_mse: 20637962.0000\n",
            "Epoch 431/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1765.3350 - mae: 1765.3350 - mse: 20052380.0000 - val_loss: 2254.6550 - val_mae: 2254.6550 - val_mse: 20354280.0000\n",
            "Epoch 432/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1815.6478 - mae: 1815.6478 - mse: 20308274.0000 - val_loss: 1891.6039 - val_mae: 1891.6039 - val_mse: 21138022.0000\n",
            "Epoch 433/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1810.7528 - mae: 1810.7528 - mse: 20251864.0000 - val_loss: 2154.4414 - val_mae: 2154.4414 - val_mse: 19099646.0000\n",
            "Epoch 434/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1783.4725 - mae: 1783.4725 - mse: 20120556.0000 - val_loss: 1772.0723 - val_mae: 1772.0723 - val_mse: 19076038.0000\n",
            "Epoch 435/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1819.6698 - mae: 1819.6698 - mse: 20883576.0000 - val_loss: 2305.5796 - val_mae: 2305.5796 - val_mse: 25174758.0000\n",
            "Epoch 436/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1800.8829 - mae: 1800.8829 - mse: 20435440.0000 - val_loss: 1916.6897 - val_mae: 1916.6897 - val_mse: 21290004.0000\n",
            "Epoch 437/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1774.1456 - mae: 1774.1456 - mse: 20573900.0000 - val_loss: 2490.6462 - val_mae: 2490.6462 - val_mse: 26311848.0000\n",
            "Epoch 438/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1821.1234 - mae: 1821.1234 - mse: 20313938.0000 - val_loss: 2103.6750 - val_mae: 2103.6750 - val_mse: 19973970.0000\n",
            "Epoch 439/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1783.6049 - mae: 1783.6049 - mse: 20231814.0000 - val_loss: 1916.9143 - val_mae: 1916.9143 - val_mse: 18897582.0000\n",
            "Epoch 440/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1761.1925 - mae: 1761.1925 - mse: 20286866.0000 - val_loss: 1713.7832 - val_mae: 1713.7832 - val_mse: 19183844.0000\n",
            "Epoch 441/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1813.7711 - mae: 1813.7711 - mse: 20401710.0000 - val_loss: 2149.4087 - val_mae: 2149.4084 - val_mse: 20141402.0000\n",
            "Epoch 442/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1792.6725 - mae: 1792.6725 - mse: 20305058.0000 - val_loss: 1870.0449 - val_mae: 1870.0449 - val_mse: 18960770.0000\n",
            "Epoch 443/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1783.2783 - mae: 1783.2783 - mse: 20169914.0000 - val_loss: 1966.5913 - val_mae: 1966.5913 - val_mse: 19292132.0000\n",
            "Epoch 444/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1776.0601 - mae: 1776.0601 - mse: 20448154.0000 - val_loss: 2223.3494 - val_mae: 2223.3494 - val_mse: 24308514.0000\n",
            "Epoch 445/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1780.1025 - mae: 1780.1025 - mse: 20307628.0000 - val_loss: 1808.0304 - val_mae: 1808.0304 - val_mse: 18855334.0000\n",
            "Epoch 446/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1820.0939 - mae: 1820.0939 - mse: 20337836.0000 - val_loss: 1977.9911 - val_mae: 1977.9911 - val_mse: 18708100.0000\n",
            "Epoch 447/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1797.4626 - mae: 1797.4626 - mse: 20765162.0000 - val_loss: 1721.9188 - val_mae: 1721.9188 - val_mse: 19326770.0000\n",
            "Epoch 448/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1764.0504 - mae: 1764.0504 - mse: 20198682.0000 - val_loss: 1816.7421 - val_mae: 1816.7421 - val_mse: 20823320.0000\n",
            "Epoch 449/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1737.5143 - mae: 1737.5143 - mse: 19849038.0000 - val_loss: 1629.7806 - val_mae: 1629.7806 - val_mse: 19358214.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 450/1000\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1778.7686 - mae: 1778.7686 - mse: 20041528.0000 - val_loss: 1775.6409 - val_mae: 1775.6409 - val_mse: 19350842.0000\n",
            "Epoch 451/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1769.4114 - mae: 1769.4114 - mse: 20210074.0000 - val_loss: 1842.1644 - val_mae: 1842.1644 - val_mse: 21834786.0000\n",
            "Epoch 452/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1799.8346 - mae: 1799.8346 - mse: 20298500.0000 - val_loss: 1776.0991 - val_mae: 1776.0991 - val_mse: 19560896.0000\n",
            "Epoch 453/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1765.4160 - mae: 1765.4160 - mse: 20228606.0000 - val_loss: 1801.2537 - val_mae: 1801.2537 - val_mse: 18901496.0000\n",
            "Epoch 454/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1769.4912 - mae: 1769.4912 - mse: 20002178.0000 - val_loss: 1802.2900 - val_mae: 1802.2900 - val_mse: 21283538.0000\n",
            "Epoch 455/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1772.0197 - mae: 1772.0197 - mse: 20040834.0000 - val_loss: 2231.9058 - val_mae: 2231.9058 - val_mse: 19659654.0000\n",
            "Epoch 456/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1742.7811 - mae: 1742.7811 - mse: 19788042.0000 - val_loss: 1766.9592 - val_mae: 1766.9592 - val_mse: 20996680.0000\n",
            "Epoch 457/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1778.5647 - mae: 1778.5647 - mse: 20140820.0000 - val_loss: 2067.2649 - val_mae: 2067.2649 - val_mse: 23350444.0000\n",
            "Epoch 458/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1798.8606 - mae: 1798.8606 - mse: 20337484.0000 - val_loss: 1732.4164 - val_mae: 1732.4164 - val_mse: 19349210.0000\n",
            "Epoch 459/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1757.9910 - mae: 1757.9910 - mse: 20414880.0000 - val_loss: 1962.9551 - val_mae: 1962.9551 - val_mse: 19975256.0000\n",
            "Epoch 460/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1766.8475 - mae: 1766.8475 - mse: 20265146.0000 - val_loss: 2423.0566 - val_mae: 2423.0566 - val_mse: 22216574.0000\n",
            "Epoch 461/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1816.2830 - mae: 1816.2830 - mse: 20644376.0000 - val_loss: 1806.6844 - val_mae: 1806.6844 - val_mse: 18861760.0000\n",
            "Epoch 462/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1789.5553 - mae: 1789.5553 - mse: 20371702.0000 - val_loss: 1859.2887 - val_mae: 1859.2887 - val_mse: 19010082.0000\n",
            "Epoch 463/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1755.8408 - mae: 1755.8408 - mse: 20000334.0000 - val_loss: 2339.1943 - val_mae: 2339.1943 - val_mse: 24682200.0000\n",
            "Epoch 464/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1733.2781 - mae: 1733.2781 - mse: 19863730.0000 - val_loss: 2080.6040 - val_mae: 2080.6040 - val_mse: 23412676.0000\n",
            "Epoch 465/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1790.5917 - mae: 1790.5917 - mse: 20313808.0000 - val_loss: 2089.1313 - val_mae: 2089.1313 - val_mse: 19359100.0000\n",
            "Epoch 466/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1765.7773 - mae: 1765.7773 - mse: 20303570.0000 - val_loss: 1982.7256 - val_mae: 1982.7256 - val_mse: 22435806.0000\n",
            "Epoch 467/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1797.5253 - mae: 1797.5253 - mse: 20361542.0000 - val_loss: 1752.0054 - val_mae: 1752.0054 - val_mse: 20601190.0000\n",
            "Epoch 468/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1743.7123 - mae: 1743.7123 - mse: 19826684.0000 - val_loss: 1862.0996 - val_mae: 1862.0996 - val_mse: 22421944.0000\n",
            "Epoch 469/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1748.1294 - mae: 1748.1294 - mse: 20278446.0000 - val_loss: 1826.0251 - val_mae: 1826.0251 - val_mse: 20591178.0000\n",
            "Epoch 470/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1711.1904 - mae: 1711.1904 - mse: 19832276.0000 - val_loss: 1833.2008 - val_mae: 1833.2008 - val_mse: 21562726.0000\n",
            "Epoch 471/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1782.8142 - mae: 1782.8142 - mse: 20300144.0000 - val_loss: 1809.5321 - val_mae: 1809.5321 - val_mse: 20617768.0000\n",
            "Epoch 472/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1698.7610 - mae: 1698.7610 - mse: 19697238.0000 - val_loss: 2327.2708 - val_mae: 2327.2708 - val_mse: 26176100.0000\n",
            "Epoch 473/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1752.2039 - mae: 1752.2039 - mse: 20280354.0000 - val_loss: 1605.7609 - val_mae: 1605.7609 - val_mse: 19612820.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 474/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1692.3318 - mae: 1692.3318 - mse: 19646508.0000 - val_loss: 1632.0815 - val_mae: 1632.0815 - val_mse: 19218732.0000\n",
            "Epoch 475/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1787.8085 - mae: 1787.8085 - mse: 20371150.0000 - val_loss: 2007.7975 - val_mae: 2007.7975 - val_mse: 19091044.0000\n",
            "Epoch 476/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1770.7777 - mae: 1770.7777 - mse: 19688676.0000 - val_loss: 1834.5659 - val_mae: 1834.5659 - val_mse: 18905524.0000\n",
            "Epoch 477/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1778.4650 - mae: 1778.4650 - mse: 20323354.0000 - val_loss: 2237.9988 - val_mae: 2237.9988 - val_mse: 23851358.0000\n",
            "Epoch 478/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1726.1876 - mae: 1726.1876 - mse: 20007496.0000 - val_loss: 1723.1429 - val_mae: 1723.1429 - val_mse: 19273060.0000\n",
            "Epoch 479/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1741.5463 - mae: 1741.5463 - mse: 19493690.0000 - val_loss: 1585.9740 - val_mae: 1585.9740 - val_mse: 19383172.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 480/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1724.1320 - mae: 1724.1320 - mse: 19634494.0000 - val_loss: 1639.1489 - val_mae: 1639.1489 - val_mse: 19648152.0000\n",
            "Epoch 481/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1746.0380 - mae: 1746.0380 - mse: 20166182.0000 - val_loss: 1844.1281 - val_mae: 1844.1281 - val_mse: 19038826.0000\n",
            "Epoch 482/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1743.4061 - mae: 1743.4061 - mse: 19906952.0000 - val_loss: 1749.1332 - val_mae: 1749.1332 - val_mse: 19784136.0000\n",
            "Epoch 483/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1828.1578 - mae: 1828.1578 - mse: 20614994.0000 - val_loss: 1749.8756 - val_mae: 1749.8756 - val_mse: 19003286.0000\n",
            "Epoch 484/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1654.3038 - mae: 1654.3038 - mse: 19386034.0000 - val_loss: 1980.3890 - val_mae: 1980.3890 - val_mse: 18845212.0000\n",
            "Epoch 485/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1751.7993 - mae: 1751.7993 - mse: 19783196.0000 - val_loss: 1695.7880 - val_mae: 1695.7880 - val_mse: 20497630.0000\n",
            "Epoch 486/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1734.7000 - mae: 1734.7000 - mse: 19927720.0000 - val_loss: 2066.0964 - val_mae: 2066.0964 - val_mse: 19562500.0000\n",
            "Epoch 487/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1751.1362 - mae: 1751.1362 - mse: 19847782.0000 - val_loss: 1744.1273 - val_mae: 1744.1273 - val_mse: 21294088.0000\n",
            "Epoch 488/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1750.1577 - mae: 1750.1577 - mse: 20228746.0000 - val_loss: 1701.9487 - val_mae: 1701.9487 - val_mse: 19416318.0000\n",
            "Epoch 489/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1764.6721 - mae: 1764.6721 - mse: 20278334.0000 - val_loss: 1716.6606 - val_mae: 1716.6606 - val_mse: 21555442.0000\n",
            "Epoch 490/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1737.9016 - mae: 1737.9016 - mse: 20014068.0000 - val_loss: 1677.3950 - val_mae: 1677.3950 - val_mse: 19242586.0000\n",
            "Epoch 491/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1749.3297 - mae: 1749.3297 - mse: 20062564.0000 - val_loss: 2172.1848 - val_mae: 2172.1848 - val_mse: 19263276.0000\n",
            "Epoch 492/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1726.2048 - mae: 1726.2048 - mse: 19827242.0000 - val_loss: 1927.6572 - val_mae: 1927.6572 - val_mse: 22698548.0000\n",
            "Epoch 493/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1709.8943 - mae: 1709.8943 - mse: 19919842.0000 - val_loss: 2360.6121 - val_mae: 2360.6121 - val_mse: 26522100.0000\n",
            "Epoch 494/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1726.5990 - mae: 1726.5990 - mse: 19974622.0000 - val_loss: 1937.4918 - val_mae: 1937.4918 - val_mse: 21716800.0000\n",
            "Epoch 495/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1720.8112 - mae: 1720.8112 - mse: 19366422.0000 - val_loss: 1817.5493 - val_mae: 1817.5493 - val_mse: 18873296.0000\n",
            "Epoch 496/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1736.7241 - mae: 1736.7241 - mse: 20141398.0000 - val_loss: 1900.8378 - val_mae: 1900.8378 - val_mse: 19505142.0000\n",
            "Epoch 497/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1725.5366 - mae: 1725.5366 - mse: 20103102.0000 - val_loss: 1685.8889 - val_mae: 1685.8889 - val_mse: 19352904.0000\n",
            "Epoch 498/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1706.3297 - mae: 1706.3297 - mse: 19457630.0000 - val_loss: 1750.2438 - val_mae: 1750.2438 - val_mse: 18889884.0000\n",
            "Epoch 499/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1708.7666 - mae: 1708.7666 - mse: 20203982.0000 - val_loss: 2546.7578 - val_mae: 2546.7578 - val_mse: 22852448.0000\n",
            "Epoch 500/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1777.0485 - mae: 1777.0485 - mse: 20256012.0000 - val_loss: 1590.6399 - val_mae: 1590.6399 - val_mse: 19433178.0000\n",
            "Epoch 501/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1740.7411 - mae: 1740.7411 - mse: 19968628.0000 - val_loss: 1903.7003 - val_mae: 1903.7003 - val_mse: 19277996.0000\n",
            "Epoch 502/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1740.0757 - mae: 1740.0757 - mse: 19774254.0000 - val_loss: 1872.2731 - val_mae: 1872.2731 - val_mse: 19175670.0000\n",
            "Epoch 503/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1699.4768 - mae: 1699.4768 - mse: 19594352.0000 - val_loss: 1848.8722 - val_mae: 1848.8722 - val_mse: 21806712.0000\n",
            "Epoch 504/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1732.0929 - mae: 1732.0929 - mse: 19862360.0000 - val_loss: 2128.8513 - val_mae: 2128.8513 - val_mse: 23260382.0000\n",
            "Epoch 505/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1692.6196 - mae: 1692.6196 - mse: 19724800.0000 - val_loss: 2186.0051 - val_mae: 2186.0051 - val_mse: 24498302.0000\n",
            "Epoch 506/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1650.8750 - mae: 1650.8751 - mse: 19133418.0000 - val_loss: 1693.7661 - val_mae: 1693.7661 - val_mse: 20454774.0000\n",
            "Epoch 507/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1714.2031 - mae: 1714.2031 - mse: 19491150.0000 - val_loss: 1876.1676 - val_mae: 1876.1676 - val_mse: 18624806.0000\n",
            "Epoch 508/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1691.9928 - mae: 1691.9928 - mse: 19345128.0000 - val_loss: 2033.2937 - val_mae: 2033.2937 - val_mse: 19571230.0000\n",
            "Epoch 509/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1793.3182 - mae: 1793.3182 - mse: 20307502.0000 - val_loss: 1766.6536 - val_mae: 1766.6536 - val_mse: 21586628.0000\n",
            "Epoch 510/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1657.1837 - mae: 1657.1837 - mse: 19264576.0000 - val_loss: 1833.9363 - val_mae: 1833.9363 - val_mse: 22246352.0000\n",
            "Epoch 511/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1724.5192 - mae: 1724.5192 - mse: 19812040.0000 - val_loss: 1745.7473 - val_mae: 1745.7473 - val_mse: 19574410.0000\n",
            "Epoch 512/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1728.6846 - mae: 1728.6846 - mse: 20072786.0000 - val_loss: 1765.7988 - val_mae: 1765.7988 - val_mse: 19325746.0000\n",
            "Epoch 513/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1688.1409 - mae: 1688.1409 - mse: 19331116.0000 - val_loss: 1878.3044 - val_mae: 1878.3044 - val_mse: 21933126.0000\n",
            "Epoch 514/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1666.0272 - mae: 1666.0272 - mse: 19727970.0000 - val_loss: 1727.9596 - val_mae: 1727.9596 - val_mse: 19623754.0000\n",
            "Epoch 515/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1746.6382 - mae: 1746.6382 - mse: 19775834.0000 - val_loss: 1779.5587 - val_mae: 1779.5587 - val_mse: 18954882.0000\n",
            "Epoch 516/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1703.9097 - mae: 1703.9097 - mse: 19773112.0000 - val_loss: 1686.9537 - val_mae: 1686.9537 - val_mse: 19824776.0000\n",
            "Epoch 517/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1743.2979 - mae: 1743.2979 - mse: 19927798.0000 - val_loss: 1751.1577 - val_mae: 1751.1577 - val_mse: 20230006.0000\n",
            "Epoch 518/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1716.7550 - mae: 1716.7550 - mse: 20111654.0000 - val_loss: 1863.2224 - val_mae: 1863.2224 - val_mse: 21242376.0000\n",
            "Epoch 519/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1693.4492 - mae: 1693.4492 - mse: 19627614.0000 - val_loss: 2063.1687 - val_mae: 2063.1687 - val_mse: 19219558.0000\n",
            "Epoch 520/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1676.1667 - mae: 1676.1667 - mse: 19243524.0000 - val_loss: 1755.6041 - val_mae: 1755.6041 - val_mse: 19500966.0000\n",
            "Epoch 521/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1674.9041 - mae: 1674.9041 - mse: 19436766.0000 - val_loss: 1798.8522 - val_mae: 1798.8522 - val_mse: 19825540.0000\n",
            "Epoch 522/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1727.7498 - mae: 1727.7498 - mse: 19729614.0000 - val_loss: 2135.7725 - val_mae: 2135.7725 - val_mse: 23072254.0000\n",
            "Epoch 523/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1767.2188 - mae: 1767.2188 - mse: 20213128.0000 - val_loss: 1754.0228 - val_mae: 1754.0228 - val_mse: 18932366.0000\n",
            "Epoch 524/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1666.6368 - mae: 1666.6368 - mse: 19618832.0000 - val_loss: 2154.7793 - val_mae: 2154.7793 - val_mse: 20792410.0000\n",
            "Epoch 525/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1744.4248 - mae: 1744.4248 - mse: 19942896.0000 - val_loss: 1703.9457 - val_mae: 1703.9457 - val_mse: 19681344.0000\n",
            "Epoch 526/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1681.3342 - mae: 1681.3342 - mse: 19510222.0000 - val_loss: 1899.9017 - val_mae: 1899.9017 - val_mse: 21681322.0000\n",
            "Epoch 527/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1667.6736 - mae: 1667.6736 - mse: 19461362.0000 - val_loss: 1706.2256 - val_mae: 1706.2256 - val_mse: 20510906.0000\n",
            "Epoch 528/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1688.7299 - mae: 1688.7299 - mse: 19874616.0000 - val_loss: 2399.8726 - val_mae: 2399.8726 - val_mse: 21825662.0000\n",
            "Epoch 529/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1709.4407 - mae: 1709.4407 - mse: 19460830.0000 - val_loss: 1752.1993 - val_mae: 1752.1993 - val_mse: 21082068.0000\n",
            "Epoch 530/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1685.6423 - mae: 1685.6423 - mse: 19581408.0000 - val_loss: 1947.9219 - val_mae: 1947.9219 - val_mse: 23164436.0000\n",
            "Epoch 531/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1701.1152 - mae: 1701.1152 - mse: 19804366.0000 - val_loss: 1629.6517 - val_mae: 1629.6517 - val_mse: 20016382.0000\n",
            "Epoch 532/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1675.7070 - mae: 1675.7070 - mse: 19419320.0000 - val_loss: 1915.0857 - val_mae: 1915.0857 - val_mse: 23322778.0000\n",
            "Epoch 533/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1738.7537 - mae: 1738.7537 - mse: 20227916.0000 - val_loss: 1879.5541 - val_mae: 1879.5541 - val_mse: 21297918.0000\n",
            "Epoch 534/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1685.3640 - mae: 1685.3640 - mse: 20117946.0000 - val_loss: 1892.1400 - val_mae: 1892.1400 - val_mse: 21525196.0000\n",
            "Epoch 535/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1724.8298 - mae: 1724.8298 - mse: 19747848.0000 - val_loss: 1605.8638 - val_mae: 1605.8638 - val_mse: 20188278.0000\n",
            "Epoch 536/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1705.7581 - mae: 1705.7581 - mse: 19234226.0000 - val_loss: 1571.7106 - val_mae: 1571.7106 - val_mse: 19641490.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 537/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1639.4927 - mae: 1639.4927 - mse: 19223602.0000 - val_loss: 1829.3320 - val_mae: 1829.3320 - val_mse: 19487506.0000\n",
            "Epoch 538/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1752.2197 - mae: 1752.2197 - mse: 20121978.0000 - val_loss: 1722.2938 - val_mae: 1722.2938 - val_mse: 20533226.0000\n",
            "Epoch 539/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1686.9161 - mae: 1686.9161 - mse: 19898650.0000 - val_loss: 1754.1160 - val_mae: 1754.1160 - val_mse: 18978728.0000\n",
            "Epoch 540/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1691.4147 - mae: 1691.4147 - mse: 19314594.0000 - val_loss: 2142.8030 - val_mae: 2142.8030 - val_mse: 23871670.0000\n",
            "Epoch 541/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1693.7000 - mae: 1693.7000 - mse: 19830564.0000 - val_loss: 1789.3435 - val_mae: 1789.3435 - val_mse: 21020448.0000\n",
            "Epoch 542/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1686.7256 - mae: 1686.7256 - mse: 19467024.0000 - val_loss: 1957.3043 - val_mae: 1957.3043 - val_mse: 18786250.0000\n",
            "Epoch 543/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1700.1798 - mae: 1700.1798 - mse: 19533510.0000 - val_loss: 1955.3274 - val_mae: 1955.3274 - val_mse: 21933082.0000\n",
            "Epoch 544/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1714.5059 - mae: 1714.5059 - mse: 19991608.0000 - val_loss: 1994.5044 - val_mae: 1994.5045 - val_mse: 22447590.0000\n",
            "Epoch 545/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1699.4971 - mae: 1699.4971 - mse: 19661760.0000 - val_loss: 1580.2390 - val_mae: 1580.2390 - val_mse: 19774748.0000\n",
            "Epoch 546/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1663.1205 - mae: 1663.1205 - mse: 19235118.0000 - val_loss: 1911.6571 - val_mae: 1911.6571 - val_mse: 19544124.0000\n",
            "Epoch 547/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1666.5957 - mae: 1666.5957 - mse: 19630522.0000 - val_loss: 1785.5399 - val_mae: 1785.5399 - val_mse: 19268444.0000\n",
            "Epoch 548/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1675.9432 - mae: 1675.9432 - mse: 19708948.0000 - val_loss: 1831.5580 - val_mae: 1831.5580 - val_mse: 22340550.0000\n",
            "Epoch 549/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1731.7759 - mae: 1731.7759 - mse: 19683726.0000 - val_loss: 1952.8726 - val_mae: 1952.8726 - val_mse: 21894172.0000\n",
            "Epoch 550/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1703.6205 - mae: 1703.6205 - mse: 19513414.0000 - val_loss: 2001.1515 - val_mae: 2001.1515 - val_mse: 19123820.0000\n",
            "Epoch 551/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1710.6392 - mae: 1710.6392 - mse: 19488704.0000 - val_loss: 1749.4264 - val_mae: 1749.4264 - val_mse: 22022448.0000\n",
            "Epoch 552/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1674.8580 - mae: 1674.8580 - mse: 19592976.0000 - val_loss: 2101.7585 - val_mae: 2101.7585 - val_mse: 19480972.0000\n",
            "Epoch 553/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1688.5729 - mae: 1688.5729 - mse: 19724896.0000 - val_loss: 1667.0503 - val_mae: 1667.0503 - val_mse: 20063112.0000\n",
            "Epoch 554/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1700.3690 - mae: 1700.3690 - mse: 19702738.0000 - val_loss: 1773.7747 - val_mae: 1773.7747 - val_mse: 21009444.0000\n",
            "Epoch 555/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1611.0587 - mae: 1611.0587 - mse: 19103294.0000 - val_loss: 1973.8068 - val_mae: 1973.8068 - val_mse: 21952978.0000\n",
            "Epoch 556/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1677.1709 - mae: 1677.1709 - mse: 19556802.0000 - val_loss: 1632.1627 - val_mae: 1632.1627 - val_mse: 20578332.0000\n",
            "Epoch 557/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1665.6024 - mae: 1665.6024 - mse: 19489004.0000 - val_loss: 1689.4963 - val_mae: 1689.4963 - val_mse: 19357160.0000\n",
            "Epoch 558/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1663.7871 - mae: 1663.7871 - mse: 19528358.0000 - val_loss: 1560.2212 - val_mae: 1560.2212 - val_mse: 19910066.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 559/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1744.5446 - mae: 1744.5446 - mse: 19722638.0000 - val_loss: 1575.9547 - val_mae: 1575.9547 - val_mse: 19633864.0000\n",
            "Epoch 560/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1678.9834 - mae: 1678.9834 - mse: 19556958.0000 - val_loss: 2170.3572 - val_mae: 2170.3572 - val_mse: 23201138.0000\n",
            "Epoch 561/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1680.0677 - mae: 1680.0677 - mse: 19307628.0000 - val_loss: 1729.8093 - val_mae: 1729.8093 - val_mse: 19789360.0000\n",
            "Epoch 562/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1679.0106 - mae: 1679.0106 - mse: 19770478.0000 - val_loss: 1585.2676 - val_mae: 1585.2676 - val_mse: 19661114.0000\n",
            "Epoch 563/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1650.6431 - mae: 1650.6431 - mse: 19105232.0000 - val_loss: 1828.6003 - val_mae: 1828.6003 - val_mse: 21484204.0000\n",
            "Epoch 564/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1678.1327 - mae: 1678.1327 - mse: 19507288.0000 - val_loss: 1627.1230 - val_mae: 1627.1230 - val_mse: 20192854.0000\n",
            "Epoch 565/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1661.9214 - mae: 1661.9214 - mse: 19683982.0000 - val_loss: 1634.3961 - val_mae: 1634.3961 - val_mse: 19391602.0000\n",
            "Epoch 566/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1672.7935 - mae: 1672.7935 - mse: 20056232.0000 - val_loss: 2653.6758 - val_mae: 2653.6758 - val_mse: 24283732.0000\n",
            "Epoch 567/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1655.4872 - mae: 1655.4872 - mse: 19429464.0000 - val_loss: 1702.2550 - val_mae: 1702.2550 - val_mse: 19061384.0000\n",
            "Epoch 568/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1731.7418 - mae: 1731.7418 - mse: 19733368.0000 - val_loss: 1582.3115 - val_mae: 1582.3115 - val_mse: 19632540.0000\n",
            "Epoch 569/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1644.1620 - mae: 1644.1620 - mse: 19076180.0000 - val_loss: 1598.8420 - val_mae: 1598.8420 - val_mse: 20102606.0000\n",
            "Epoch 570/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1694.7941 - mae: 1694.7941 - mse: 19712006.0000 - val_loss: 1547.0092 - val_mae: 1547.0092 - val_mse: 19681040.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 571/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1677.4971 - mae: 1677.4971 - mse: 19334952.0000 - val_loss: 1686.9463 - val_mae: 1686.9463 - val_mse: 20854612.0000\n",
            "Epoch 572/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1688.2806 - mae: 1688.2806 - mse: 19299680.0000 - val_loss: 1786.7644 - val_mae: 1786.7644 - val_mse: 22160284.0000\n",
            "Epoch 573/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1649.2716 - mae: 1649.2716 - mse: 19276198.0000 - val_loss: 2435.5291 - val_mae: 2435.5291 - val_mse: 27169572.0000\n",
            "Epoch 574/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1674.3280 - mae: 1674.3280 - mse: 19414544.0000 - val_loss: 1545.5939 - val_mae: 1545.5939 - val_mse: 19537452.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 575/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1662.9142 - mae: 1662.9142 - mse: 19396902.0000 - val_loss: 2018.5164 - val_mae: 2018.5164 - val_mse: 22587292.0000\n",
            "Epoch 576/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1665.9781 - mae: 1665.9781 - mse: 19626342.0000 - val_loss: 1648.6329 - val_mae: 1648.6329 - val_mse: 19404322.0000\n",
            "Epoch 577/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1731.9481 - mae: 1731.9481 - mse: 20326716.0000 - val_loss: 1787.2104 - val_mae: 1787.2104 - val_mse: 18874732.0000\n",
            "Epoch 578/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1679.9927 - mae: 1679.9927 - mse: 19517734.0000 - val_loss: 1581.9515 - val_mae: 1581.9515 - val_mse: 20082410.0000\n",
            "Epoch 579/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1682.8201 - mae: 1682.8201 - mse: 19754744.0000 - val_loss: 1612.5327 - val_mae: 1612.5327 - val_mse: 20788124.0000\n",
            "Epoch 580/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1630.3282 - mae: 1630.3282 - mse: 19454654.0000 - val_loss: 1709.5786 - val_mae: 1709.5786 - val_mse: 20875460.0000\n",
            "Epoch 581/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1697.0514 - mae: 1697.0514 - mse: 19196868.0000 - val_loss: 1934.2717 - val_mae: 1934.2717 - val_mse: 22292428.0000\n",
            "Epoch 582/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1648.9834 - mae: 1648.9834 - mse: 19595406.0000 - val_loss: 1634.2573 - val_mae: 1634.2573 - val_mse: 20396704.0000\n",
            "Epoch 583/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1685.6174 - mae: 1685.6174 - mse: 19455262.0000 - val_loss: 1714.5901 - val_mae: 1714.5901 - val_mse: 19078630.0000\n",
            "Epoch 584/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1656.9160 - mae: 1656.9160 - mse: 19456776.0000 - val_loss: 1860.5172 - val_mae: 1860.5172 - val_mse: 18855052.0000\n",
            "Epoch 585/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1692.7200 - mae: 1692.7200 - mse: 19851530.0000 - val_loss: 1560.3569 - val_mae: 1560.3569 - val_mse: 19493340.0000\n",
            "Epoch 586/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1649.0804 - mae: 1649.0804 - mse: 19360008.0000 - val_loss: 1903.3020 - val_mae: 1903.3020 - val_mse: 19839600.0000\n",
            "Epoch 587/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.0702 - mae: 1665.0702 - mse: 19642314.0000 - val_loss: 1819.9199 - val_mae: 1819.9199 - val_mse: 18925562.0000\n",
            "Epoch 588/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1677.8811 - mae: 1677.8811 - mse: 19290674.0000 - val_loss: 1698.3131 - val_mae: 1698.3131 - val_mse: 20303984.0000\n",
            "Epoch 589/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1682.4771 - mae: 1682.4771 - mse: 19831092.0000 - val_loss: 1924.6794 - val_mae: 1924.6794 - val_mse: 23164756.0000\n",
            "Epoch 590/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1669.0597 - mae: 1669.0597 - mse: 19450888.0000 - val_loss: 1776.2639 - val_mae: 1776.2639 - val_mse: 21015878.0000\n",
            "Epoch 591/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1638.6394 - mae: 1638.6394 - mse: 19250190.0000 - val_loss: 2118.2561 - val_mae: 2118.2561 - val_mse: 22659836.0000\n",
            "Epoch 592/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1687.8313 - mae: 1687.8313 - mse: 19369138.0000 - val_loss: 1746.3055 - val_mae: 1746.3055 - val_mse: 18996470.0000\n",
            "Epoch 593/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1631.4181 - mae: 1631.4181 - mse: 19039420.0000 - val_loss: 2290.9131 - val_mae: 2290.9131 - val_mse: 25563582.0000\n",
            "Epoch 594/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1662.2788 - mae: 1662.2788 - mse: 19453422.0000 - val_loss: 1694.6943 - val_mae: 1694.6943 - val_mse: 20527324.0000\n",
            "Epoch 595/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1644.6390 - mae: 1644.6390 - mse: 19648670.0000 - val_loss: 1678.8790 - val_mae: 1678.8790 - val_mse: 21132530.0000\n",
            "Epoch 596/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1663.6005 - mae: 1663.6005 - mse: 19286520.0000 - val_loss: 1727.5876 - val_mae: 1727.5876 - val_mse: 20570360.0000\n",
            "Epoch 597/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1671.4834 - mae: 1671.4834 - mse: 19404806.0000 - val_loss: 1998.7413 - val_mae: 1998.7413 - val_mse: 19090032.0000\n",
            "Epoch 598/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1659.1316 - mae: 1659.1316 - mse: 19397106.0000 - val_loss: 1576.5122 - val_mae: 1576.5122 - val_mse: 19676210.0000\n",
            "Epoch 599/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1669.5139 - mae: 1669.5139 - mse: 19497580.0000 - val_loss: 1626.3617 - val_mae: 1626.3617 - val_mse: 19381398.0000\n",
            "Epoch 600/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1650.8959 - mae: 1650.8959 - mse: 19279140.0000 - val_loss: 1684.6215 - val_mae: 1684.6215 - val_mse: 19167398.0000\n",
            "Epoch 601/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1677.3182 - mae: 1677.3182 - mse: 19845056.0000 - val_loss: 1595.4828 - val_mae: 1595.4828 - val_mse: 20267512.0000\n",
            "Epoch 602/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1660.5438 - mae: 1660.5438 - mse: 19242402.0000 - val_loss: 1787.1771 - val_mae: 1787.1771 - val_mse: 20783956.0000\n",
            "Epoch 603/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1652.0061 - mae: 1652.0061 - mse: 19457694.0000 - val_loss: 1609.4888 - val_mae: 1609.4888 - val_mse: 20209266.0000\n",
            "Epoch 604/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.1965 - mae: 1665.1965 - mse: 19823796.0000 - val_loss: 1987.2433 - val_mae: 1987.2433 - val_mse: 18894240.0000\n",
            "Epoch 605/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1699.6694 - mae: 1699.6694 - mse: 19444092.0000 - val_loss: 1587.5051 - val_mae: 1587.5051 - val_mse: 19695794.0000\n",
            "Epoch 606/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1676.6971 - mae: 1676.6971 - mse: 19412926.0000 - val_loss: 1733.4113 - val_mae: 1733.4113 - val_mse: 19236374.0000\n",
            "Epoch 607/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1643.7881 - mae: 1643.7881 - mse: 19132856.0000 - val_loss: 1953.5831 - val_mae: 1953.5831 - val_mse: 21585344.0000\n",
            "Epoch 608/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1656.9232 - mae: 1656.9232 - mse: 19480762.0000 - val_loss: 1793.5105 - val_mae: 1793.5105 - val_mse: 20875954.0000\n",
            "Epoch 609/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1642.9786 - mae: 1642.9786 - mse: 19294564.0000 - val_loss: 1864.7789 - val_mae: 1864.7789 - val_mse: 24020136.0000\n",
            "Epoch 610/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1655.1755 - mae: 1655.1755 - mse: 19743622.0000 - val_loss: 1624.2573 - val_mae: 1624.2573 - val_mse: 19285696.0000\n",
            "Epoch 611/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1613.0914 - mae: 1613.0914 - mse: 18700422.0000 - val_loss: 1685.1440 - val_mae: 1685.1440 - val_mse: 20778386.0000\n",
            "Epoch 612/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1687.7843 - mae: 1687.7843 - mse: 19606612.0000 - val_loss: 1661.8231 - val_mae: 1661.8231 - val_mse: 19496142.0000\n",
            "Epoch 613/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1638.4670 - mae: 1638.4670 - mse: 19582886.0000 - val_loss: 1617.7137 - val_mae: 1617.7137 - val_mse: 20575290.0000\n",
            "Epoch 614/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1639.0469 - mae: 1639.0469 - mse: 19366392.0000 - val_loss: 1781.7368 - val_mae: 1781.7368 - val_mse: 20410512.0000\n",
            "Epoch 615/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1672.3837 - mae: 1672.3837 - mse: 19822290.0000 - val_loss: 1661.1465 - val_mae: 1661.1465 - val_mse: 21107276.0000\n",
            "Epoch 616/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1620.3804 - mae: 1620.3804 - mse: 19316880.0000 - val_loss: 1628.3793 - val_mae: 1628.3793 - val_mse: 20693346.0000\n",
            "Epoch 617/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1590.3046 - mae: 1590.3046 - mse: 19104440.0000 - val_loss: 1903.0461 - val_mae: 1903.0461 - val_mse: 23411386.0000\n",
            "Epoch 618/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1691.4115 - mae: 1691.4115 - mse: 19540040.0000 - val_loss: 1636.6987 - val_mae: 1636.6987 - val_mse: 19982610.0000\n",
            "Epoch 619/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1659.8093 - mae: 1659.8093 - mse: 19525264.0000 - val_loss: 1901.9902 - val_mae: 1901.9902 - val_mse: 18868708.0000\n",
            "Epoch 620/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1661.3989 - mae: 1661.3989 - mse: 19032634.0000 - val_loss: 1737.6896 - val_mae: 1737.6896 - val_mse: 19891738.0000\n",
            "Epoch 621/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1676.2156 - mae: 1676.2156 - mse: 19771508.0000 - val_loss: 2059.7786 - val_mae: 2059.7786 - val_mse: 22589652.0000\n",
            "Epoch 622/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1617.6243 - mae: 1617.6243 - mse: 19314244.0000 - val_loss: 1853.8840 - val_mae: 1853.8840 - val_mse: 18825800.0000\n",
            "Epoch 623/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1648.6213 - mae: 1648.6213 - mse: 19366670.0000 - val_loss: 1550.5394 - val_mae: 1550.5394 - val_mse: 19759938.0000\n",
            "Epoch 624/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1629.6160 - mae: 1629.6160 - mse: 19354452.0000 - val_loss: 1728.9858 - val_mae: 1728.9858 - val_mse: 19829146.0000\n",
            "Epoch 625/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1716.1327 - mae: 1716.1327 - mse: 19908860.0000 - val_loss: 1582.5020 - val_mae: 1582.5020 - val_mse: 19235886.0000\n",
            "Epoch 626/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1652.9733 - mae: 1652.9733 - mse: 19040200.0000 - val_loss: 1555.2412 - val_mae: 1555.2412 - val_mse: 19439882.0000\n",
            "Epoch 627/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1626.8197 - mae: 1626.8197 - mse: 19249246.0000 - val_loss: 2105.0337 - val_mae: 2105.0337 - val_mse: 23586422.0000\n",
            "Epoch 628/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1686.2041 - mae: 1686.2041 - mse: 19831594.0000 - val_loss: 1534.4752 - val_mae: 1534.4752 - val_mse: 19420796.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 629/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1694.1173 - mae: 1694.1173 - mse: 19626268.0000 - val_loss: 1854.0341 - val_mae: 1854.0341 - val_mse: 18677402.0000\n",
            "Epoch 630/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1644.3146 - mae: 1644.3146 - mse: 19045552.0000 - val_loss: 1540.0806 - val_mae: 1540.0806 - val_mse: 19796722.0000\n",
            "Epoch 631/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1644.4214 - mae: 1644.4214 - mse: 19138738.0000 - val_loss: 1981.5844 - val_mae: 1981.5844 - val_mse: 19009346.0000\n",
            "Epoch 632/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1662.5277 - mae: 1662.5277 - mse: 19566700.0000 - val_loss: 1830.0950 - val_mae: 1830.0950 - val_mse: 18781798.0000\n",
            "Epoch 633/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1640.2706 - mae: 1640.2706 - mse: 19615750.0000 - val_loss: 1720.5164 - val_mae: 1720.5164 - val_mse: 19022388.0000\n",
            "Epoch 634/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1635.1102 - mae: 1635.1102 - mse: 19121102.0000 - val_loss: 1633.7871 - val_mae: 1633.7871 - val_mse: 21173858.0000\n",
            "Epoch 635/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1634.2480 - mae: 1634.2480 - mse: 19244714.0000 - val_loss: 1793.5608 - val_mae: 1793.5608 - val_mse: 18785310.0000\n",
            "Epoch 636/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1615.4062 - mae: 1615.4062 - mse: 19239254.0000 - val_loss: 1691.6251 - val_mae: 1691.6251 - val_mse: 19101064.0000\n",
            "Epoch 637/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1672.4187 - mae: 1672.4187 - mse: 19389746.0000 - val_loss: 1833.3033 - val_mae: 1833.3033 - val_mse: 21340192.0000\n",
            "Epoch 638/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1691.4277 - mae: 1691.4277 - mse: 19843572.0000 - val_loss: 1551.2018 - val_mae: 1551.2018 - val_mse: 19828392.0000\n",
            "Epoch 639/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1601.1952 - mae: 1601.1952 - mse: 19046732.0000 - val_loss: 1678.1063 - val_mae: 1678.1063 - val_mse: 20710024.0000\n",
            "Epoch 640/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1636.6646 - mae: 1636.6646 - mse: 19440624.0000 - val_loss: 1681.3705 - val_mae: 1681.3705 - val_mse: 20423288.0000\n",
            "Epoch 641/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1664.9735 - mae: 1664.9735 - mse: 19412960.0000 - val_loss: 1578.2396 - val_mae: 1578.2396 - val_mse: 20085136.0000\n",
            "Epoch 642/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1629.1532 - mae: 1629.1532 - mse: 19324472.0000 - val_loss: 1765.1509 - val_mae: 1765.1509 - val_mse: 22790512.0000\n",
            "Epoch 643/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1606.7878 - mae: 1606.7878 - mse: 19486898.0000 - val_loss: 2369.7842 - val_mae: 2369.7842 - val_mse: 25033048.0000\n",
            "Epoch 644/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1695.7125 - mae: 1695.7125 - mse: 19951160.0000 - val_loss: 1731.5211 - val_mae: 1731.5211 - val_mse: 18738008.0000\n",
            "Epoch 645/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1625.9087 - mae: 1625.9087 - mse: 19357876.0000 - val_loss: 2279.2649 - val_mae: 2279.2649 - val_mse: 20014906.0000\n",
            "Epoch 646/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1685.5729 - mae: 1685.5729 - mse: 19642620.0000 - val_loss: 2033.7921 - val_mae: 2033.7921 - val_mse: 23977626.0000\n",
            "Epoch 647/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1646.9058 - mae: 1646.9058 - mse: 19341382.0000 - val_loss: 2171.8948 - val_mae: 2171.8948 - val_mse: 25333008.0000\n",
            "Epoch 648/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1640.8699 - mae: 1640.8699 - mse: 19317608.0000 - val_loss: 2048.2527 - val_mae: 2048.2527 - val_mse: 22298736.0000\n",
            "Epoch 649/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1656.3247 - mae: 1656.3247 - mse: 19521652.0000 - val_loss: 1598.3195 - val_mae: 1598.3195 - val_mse: 19241834.0000\n",
            "Epoch 650/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1634.4152 - mae: 1634.4152 - mse: 19444950.0000 - val_loss: 1771.2292 - val_mae: 1771.2292 - val_mse: 19202258.0000\n",
            "Epoch 651/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1659.6124 - mae: 1659.6124 - mse: 19503034.0000 - val_loss: 2040.2681 - val_mae: 2040.2683 - val_mse: 23321406.0000\n",
            "Epoch 652/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1663.9253 - mae: 1663.9253 - mse: 19451718.0000 - val_loss: 2297.6465 - val_mae: 2297.6465 - val_mse: 26297092.0000\n",
            "Epoch 653/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1652.2822 - mae: 1652.2822 - mse: 19362288.0000 - val_loss: 1660.4442 - val_mae: 1660.4442 - val_mse: 18888934.0000\n",
            "Epoch 654/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1600.2537 - mae: 1600.2537 - mse: 18946164.0000 - val_loss: 1786.0946 - val_mae: 1786.0946 - val_mse: 19185196.0000\n",
            "Epoch 655/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1618.5433 - mae: 1618.5433 - mse: 19389898.0000 - val_loss: 1847.8242 - val_mae: 1847.8242 - val_mse: 20035290.0000\n",
            "Epoch 656/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1660.1553 - mae: 1660.1553 - mse: 19608642.0000 - val_loss: 1629.5332 - val_mae: 1629.5332 - val_mse: 20589996.0000\n",
            "Epoch 657/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1606.4440 - mae: 1606.4440 - mse: 18839870.0000 - val_loss: 1578.6898 - val_mae: 1578.6898 - val_mse: 20389452.0000\n",
            "Epoch 658/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1648.4253 - mae: 1648.4254 - mse: 19525044.0000 - val_loss: 2054.1182 - val_mae: 2054.1182 - val_mse: 19097024.0000\n",
            "Epoch 659/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1670.3353 - mae: 1670.3353 - mse: 19399676.0000 - val_loss: 1679.1041 - val_mae: 1679.1041 - val_mse: 18999846.0000\n",
            "Epoch 660/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1614.2150 - mae: 1614.2150 - mse: 18998516.0000 - val_loss: 1730.0818 - val_mae: 1730.0818 - val_mse: 22710378.0000\n",
            "Epoch 661/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1645.2316 - mae: 1645.2316 - mse: 19566136.0000 - val_loss: 1629.9414 - val_mae: 1629.9414 - val_mse: 19182462.0000\n",
            "Epoch 662/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1628.2609 - mae: 1628.2609 - mse: 18931388.0000 - val_loss: 1710.5039 - val_mae: 1710.5039 - val_mse: 19371180.0000\n",
            "Epoch 663/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1635.1704 - mae: 1635.1704 - mse: 19233312.0000 - val_loss: 1731.2739 - val_mae: 1731.2739 - val_mse: 21557650.0000\n",
            "Epoch 664/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1611.2424 - mae: 1611.2424 - mse: 19394234.0000 - val_loss: 1874.3671 - val_mae: 1874.3671 - val_mse: 18792604.0000\n",
            "Epoch 665/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1638.0660 - mae: 1638.0660 - mse: 19116166.0000 - val_loss: 1791.8521 - val_mae: 1791.8521 - val_mse: 18872658.0000\n",
            "Epoch 666/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1627.8177 - mae: 1627.8177 - mse: 19277958.0000 - val_loss: 2082.3398 - val_mae: 2082.3398 - val_mse: 24184684.0000\n",
            "Epoch 667/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1651.7523 - mae: 1651.7523 - mse: 19255174.0000 - val_loss: 1889.6792 - val_mae: 1889.6792 - val_mse: 21986158.0000\n",
            "Epoch 668/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1651.1101 - mae: 1651.1101 - mse: 19369876.0000 - val_loss: 1767.3849 - val_mae: 1767.3849 - val_mse: 21641814.0000\n",
            "Epoch 669/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1641.0826 - mae: 1641.0826 - mse: 19584264.0000 - val_loss: 1935.2472 - val_mae: 1935.2472 - val_mse: 22774580.0000\n",
            "Epoch 670/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1645.1428 - mae: 1645.1428 - mse: 19643134.0000 - val_loss: 1692.4373 - val_mae: 1692.4373 - val_mse: 20875176.0000\n",
            "Epoch 671/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1674.7565 - mae: 1674.7565 - mse: 19649354.0000 - val_loss: 1677.2800 - val_mae: 1677.2800 - val_mse: 20611868.0000\n",
            "Epoch 672/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1615.1101 - mae: 1615.1101 - mse: 19263682.0000 - val_loss: 1724.6703 - val_mae: 1724.6703 - val_mse: 21057490.0000\n",
            "Epoch 673/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1611.3584 - mae: 1611.3584 - mse: 18891196.0000 - val_loss: 2133.5432 - val_mae: 2133.5432 - val_mse: 24150390.0000\n",
            "Epoch 674/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1655.1115 - mae: 1655.1115 - mse: 19557354.0000 - val_loss: 1787.7433 - val_mae: 1787.7433 - val_mse: 18829114.0000\n",
            "Epoch 675/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1639.7576 - mae: 1639.7576 - mse: 19384446.0000 - val_loss: 1624.3604 - val_mae: 1624.3604 - val_mse: 18893874.0000\n",
            "Epoch 676/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1584.5410 - mae: 1584.5410 - mse: 18901574.0000 - val_loss: 1670.5999 - val_mae: 1670.5999 - val_mse: 18840844.0000\n",
            "Epoch 677/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1646.4285 - mae: 1646.4285 - mse: 19614638.0000 - val_loss: 1506.3729 - val_mae: 1506.3729 - val_mse: 19406918.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 678/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1639.5486 - mae: 1639.5486 - mse: 19200150.0000 - val_loss: 1564.2100 - val_mae: 1564.2100 - val_mse: 20166926.0000\n",
            "Epoch 679/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1606.2917 - mae: 1606.2917 - mse: 19284564.0000 - val_loss: 1561.2760 - val_mae: 1561.2760 - val_mse: 18877568.0000\n",
            "Epoch 680/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1669.0972 - mae: 1669.0972 - mse: 20140376.0000 - val_loss: 1634.9138 - val_mae: 1634.9138 - val_mse: 20709058.0000\n",
            "Epoch 681/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1660.7971 - mae: 1660.7971 - mse: 19789558.0000 - val_loss: 1598.7230 - val_mae: 1598.7230 - val_mse: 19545196.0000\n",
            "Epoch 682/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1614.3175 - mae: 1614.3175 - mse: 19288934.0000 - val_loss: 2041.0154 - val_mae: 2041.0154 - val_mse: 21935154.0000\n",
            "Epoch 683/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1652.6691 - mae: 1652.6692 - mse: 19290692.0000 - val_loss: 1660.0081 - val_mae: 1660.0081 - val_mse: 18981184.0000\n",
            "Epoch 684/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1577.7946 - mae: 1577.7946 - mse: 18876806.0000 - val_loss: 1593.9397 - val_mae: 1593.9397 - val_mse: 20244672.0000\n",
            "Epoch 685/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1624.7743 - mae: 1624.7743 - mse: 19308798.0000 - val_loss: 1943.6921 - val_mae: 1943.6921 - val_mse: 22553410.0000\n",
            "Epoch 686/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1593.6628 - mae: 1593.6628 - mse: 18898198.0000 - val_loss: 1807.1914 - val_mae: 1807.1914 - val_mse: 18689922.0000\n",
            "Epoch 687/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1655.3440 - mae: 1655.3440 - mse: 19720728.0000 - val_loss: 2104.8914 - val_mae: 2104.8914 - val_mse: 22776040.0000\n",
            "Epoch 688/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1627.6418 - mae: 1627.6418 - mse: 19393138.0000 - val_loss: 1622.6593 - val_mae: 1622.6593 - val_mse: 20155514.0000\n",
            "Epoch 689/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1611.2902 - mae: 1611.2902 - mse: 19120966.0000 - val_loss: 1832.7609 - val_mae: 1832.7609 - val_mse: 19118942.0000\n",
            "Epoch 690/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1645.5973 - mae: 1645.5973 - mse: 19249574.0000 - val_loss: 1669.0862 - val_mae: 1669.0862 - val_mse: 19091828.0000\n",
            "Epoch 691/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1591.3394 - mae: 1591.3394 - mse: 18648422.0000 - val_loss: 1495.1952 - val_mae: 1495.1952 - val_mse: 19735124.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 692/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1610.0166 - mae: 1610.0166 - mse: 18964772.0000 - val_loss: 1566.8936 - val_mae: 1566.8936 - val_mse: 20142156.0000\n",
            "Epoch 693/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1654.5538 - mae: 1654.5538 - mse: 19266990.0000 - val_loss: 1757.2853 - val_mae: 1757.2853 - val_mse: 18633340.0000\n",
            "Epoch 694/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1616.0741 - mae: 1616.0741 - mse: 19204706.0000 - val_loss: 1683.3182 - val_mae: 1683.3182 - val_mse: 21305138.0000\n",
            "Epoch 695/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1642.7380 - mae: 1642.7380 - mse: 19212726.0000 - val_loss: 1749.7454 - val_mae: 1749.7454 - val_mse: 21505288.0000\n",
            "Epoch 696/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1634.9935 - mae: 1634.9935 - mse: 19190508.0000 - val_loss: 1669.5714 - val_mae: 1669.5714 - val_mse: 18922378.0000\n",
            "Epoch 697/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1617.4689 - mae: 1617.4689 - mse: 19254800.0000 - val_loss: 1613.8262 - val_mae: 1613.8262 - val_mse: 20711376.0000\n",
            "Epoch 698/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1657.4087 - mae: 1657.4087 - mse: 19245804.0000 - val_loss: 2091.6384 - val_mae: 2091.6384 - val_mse: 19681164.0000\n",
            "Epoch 699/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1617.3313 - mae: 1617.3313 - mse: 19144020.0000 - val_loss: 2121.3635 - val_mae: 2121.3635 - val_mse: 23561788.0000\n",
            "Epoch 700/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1648.3438 - mae: 1648.3438 - mse: 19356924.0000 - val_loss: 1658.8335 - val_mae: 1658.8335 - val_mse: 21107070.0000\n",
            "Epoch 701/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1577.0284 - mae: 1577.0284 - mse: 19049756.0000 - val_loss: 1696.2401 - val_mae: 1696.2401 - val_mse: 19892476.0000\n",
            "Epoch 702/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1601.9895 - mae: 1601.9895 - mse: 19225334.0000 - val_loss: 1925.9799 - val_mae: 1925.9799 - val_mse: 22415898.0000\n",
            "Epoch 703/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1639.5665 - mae: 1639.5665 - mse: 19232014.0000 - val_loss: 1725.7275 - val_mae: 1725.7275 - val_mse: 18536348.0000\n",
            "Epoch 704/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1630.6080 - mae: 1630.6080 - mse: 19169648.0000 - val_loss: 1599.2021 - val_mae: 1599.2021 - val_mse: 19553826.0000\n",
            "Epoch 705/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1604.3214 - mae: 1604.3214 - mse: 19205582.0000 - val_loss: 1788.1891 - val_mae: 1788.1891 - val_mse: 22831644.0000\n",
            "Epoch 706/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1635.8356 - mae: 1635.8356 - mse: 19684348.0000 - val_loss: 1743.0461 - val_mae: 1743.0461 - val_mse: 21637270.0000\n",
            "Epoch 707/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1613.9437 - mae: 1613.9437 - mse: 19175196.0000 - val_loss: 1663.8435 - val_mae: 1663.8435 - val_mse: 20733588.0000\n",
            "Epoch 708/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1623.8043 - mae: 1623.8043 - mse: 19392384.0000 - val_loss: 1528.0581 - val_mae: 1528.0581 - val_mse: 19905282.0000\n",
            "Epoch 709/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1645.0400 - mae: 1645.0400 - mse: 19460654.0000 - val_loss: 1835.8921 - val_mae: 1835.8921 - val_mse: 19101802.0000\n",
            "Epoch 710/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1574.8755 - mae: 1574.8755 - mse: 18828466.0000 - val_loss: 1934.1420 - val_mae: 1934.1420 - val_mse: 22358780.0000\n",
            "Epoch 711/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1630.6212 - mae: 1630.6212 - mse: 19217214.0000 - val_loss: 1783.5841 - val_mae: 1783.5841 - val_mse: 18734918.0000\n",
            "Epoch 712/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1648.8738 - mae: 1648.8738 - mse: 19147152.0000 - val_loss: 1924.5225 - val_mae: 1924.5225 - val_mse: 22533518.0000\n",
            "Epoch 713/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1589.7164 - mae: 1589.7164 - mse: 19387344.0000 - val_loss: 1805.2462 - val_mae: 1805.2462 - val_mse: 21381326.0000\n",
            "Epoch 714/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1637.8656 - mae: 1637.8656 - mse: 19352770.0000 - val_loss: 1703.8810 - val_mae: 1703.8810 - val_mse: 18813426.0000\n",
            "Epoch 715/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1664.1461 - mae: 1664.1461 - mse: 19610848.0000 - val_loss: 1498.1384 - val_mae: 1498.1384 - val_mse: 19806742.0000\n",
            "Epoch 716/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1596.2566 - mae: 1596.2566 - mse: 19206414.0000 - val_loss: 1894.9666 - val_mae: 1894.9666 - val_mse: 19100876.0000\n",
            "Epoch 717/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1614.3680 - mae: 1614.3680 - mse: 19154092.0000 - val_loss: 1716.7732 - val_mae: 1716.7732 - val_mse: 19180478.0000\n",
            "Epoch 718/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1657.8503 - mae: 1657.8503 - mse: 19161514.0000 - val_loss: 1531.4733 - val_mae: 1531.4733 - val_mse: 19694546.0000\n",
            "Epoch 719/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1607.7271 - mae: 1607.7271 - mse: 19233480.0000 - val_loss: 1762.0382 - val_mae: 1762.0382 - val_mse: 18896632.0000\n",
            "Epoch 720/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1613.2767 - mae: 1613.2767 - mse: 18864182.0000 - val_loss: 1515.2024 - val_mae: 1515.2024 - val_mse: 19850964.0000\n",
            "Epoch 721/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.3499 - mae: 1593.3499 - mse: 18856044.0000 - val_loss: 1601.0771 - val_mae: 1601.0771 - val_mse: 19944522.0000\n",
            "Epoch 722/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1607.5880 - mae: 1607.5880 - mse: 19131808.0000 - val_loss: 2076.0769 - val_mae: 2076.0769 - val_mse: 23879708.0000\n",
            "Epoch 723/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1658.9381 - mae: 1658.9381 - mse: 19356058.0000 - val_loss: 1665.1459 - val_mae: 1665.1459 - val_mse: 20816318.0000\n",
            "Epoch 724/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1622.9670 - mae: 1622.9670 - mse: 19280846.0000 - val_loss: 1501.4221 - val_mae: 1501.4221 - val_mse: 19454176.0000\n",
            "Epoch 725/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1628.4768 - mae: 1628.4768 - mse: 19513068.0000 - val_loss: 2072.9424 - val_mae: 2072.9424 - val_mse: 19319738.0000\n",
            "Epoch 726/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1645.2246 - mae: 1645.2246 - mse: 19647304.0000 - val_loss: 1709.0779 - val_mae: 1709.0779 - val_mse: 21335792.0000\n",
            "Epoch 727/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1602.9800 - mae: 1602.9800 - mse: 18992590.0000 - val_loss: 1744.7275 - val_mae: 1744.7275 - val_mse: 18962240.0000\n",
            "Epoch 728/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1644.4644 - mae: 1644.4644 - mse: 19665536.0000 - val_loss: 2180.7693 - val_mae: 2180.7693 - val_mse: 24272068.0000\n",
            "Epoch 729/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1608.5121 - mae: 1608.5121 - mse: 19200716.0000 - val_loss: 1480.9039 - val_mae: 1480.9039 - val_mse: 19310310.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 730/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1636.4823 - mae: 1636.4823 - mse: 19333168.0000 - val_loss: 1769.4023 - val_mae: 1769.4023 - val_mse: 19655660.0000\n",
            "Epoch 731/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1605.9620 - mae: 1605.9620 - mse: 19098114.0000 - val_loss: 1578.9846 - val_mae: 1578.9846 - val_mse: 19597572.0000\n",
            "Epoch 732/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1592.3105 - mae: 1592.3105 - mse: 18889178.0000 - val_loss: 1515.8356 - val_mae: 1515.8356 - val_mse: 19388658.0000\n",
            "Epoch 733/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1611.2404 - mae: 1611.2404 - mse: 18895386.0000 - val_loss: 1547.4335 - val_mae: 1547.4335 - val_mse: 19906528.0000\n",
            "Epoch 734/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1626.7971 - mae: 1626.7971 - mse: 19082104.0000 - val_loss: 1568.8618 - val_mae: 1568.8618 - val_mse: 19962006.0000\n",
            "Epoch 735/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.6013 - mae: 1588.6013 - mse: 19075160.0000 - val_loss: 1524.0211 - val_mae: 1524.0211 - val_mse: 20218674.0000\n",
            "Epoch 736/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1626.7904 - mae: 1626.7904 - mse: 19120502.0000 - val_loss: 1771.6125 - val_mae: 1771.6125 - val_mse: 19136300.0000\n",
            "Epoch 737/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1600.4154 - mae: 1600.4154 - mse: 18919696.0000 - val_loss: 2272.7639 - val_mae: 2272.7639 - val_mse: 21615182.0000\n",
            "Epoch 738/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1612.0038 - mae: 1612.0038 - mse: 18912386.0000 - val_loss: 1757.5114 - val_mae: 1757.5114 - val_mse: 19278188.0000\n",
            "Epoch 739/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1607.5665 - mae: 1607.5665 - mse: 19204420.0000 - val_loss: 1627.1973 - val_mae: 1627.1973 - val_mse: 20681630.0000\n",
            "Epoch 740/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1628.5645 - mae: 1628.5645 - mse: 19271108.0000 - val_loss: 2096.6235 - val_mae: 2096.6235 - val_mse: 24686582.0000\n",
            "Epoch 741/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1637.7173 - mae: 1637.7173 - mse: 19047912.0000 - val_loss: 1903.8820 - val_mae: 1903.8820 - val_mse: 22203976.0000\n",
            "Epoch 742/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1603.5747 - mae: 1603.5747 - mse: 18975754.0000 - val_loss: 1970.5575 - val_mae: 1970.5575 - val_mse: 19822088.0000\n",
            "Epoch 743/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1617.8262 - mae: 1617.8262 - mse: 19385690.0000 - val_loss: 1797.9196 - val_mae: 1797.9196 - val_mse: 22039640.0000\n",
            "Epoch 744/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1628.2516 - mae: 1628.2516 - mse: 19130822.0000 - val_loss: 1665.7045 - val_mae: 1665.7045 - val_mse: 21251778.0000\n",
            "Epoch 745/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1624.6814 - mae: 1624.6814 - mse: 19287988.0000 - val_loss: 1636.1434 - val_mae: 1636.1434 - val_mse: 20554652.0000\n",
            "Epoch 746/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.1002 - mae: 1593.1002 - mse: 18978144.0000 - val_loss: 1650.8971 - val_mae: 1650.8971 - val_mse: 19280162.0000\n",
            "Epoch 747/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1651.8198 - mae: 1651.8198 - mse: 19355136.0000 - val_loss: 1553.8668 - val_mae: 1553.8668 - val_mse: 20192562.0000\n",
            "Epoch 748/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1621.2375 - mae: 1621.2375 - mse: 19336252.0000 - val_loss: 1757.4281 - val_mae: 1757.4281 - val_mse: 22092114.0000\n",
            "Epoch 749/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1637.8485 - mae: 1637.8485 - mse: 19127524.0000 - val_loss: 1968.0604 - val_mae: 1968.0604 - val_mse: 20081428.0000\n",
            "Epoch 750/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1606.5040 - mae: 1606.5040 - mse: 19285972.0000 - val_loss: 1752.6145 - val_mae: 1752.6145 - val_mse: 19327460.0000\n",
            "Epoch 751/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1635.7848 - mae: 1635.7848 - mse: 19360338.0000 - val_loss: 1516.6962 - val_mae: 1516.6962 - val_mse: 19953876.0000\n",
            "Epoch 752/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1601.2190 - mae: 1601.2190 - mse: 19164070.0000 - val_loss: 1608.5767 - val_mae: 1608.5767 - val_mse: 20067088.0000\n",
            "Epoch 753/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1609.1930 - mae: 1609.1930 - mse: 18864748.0000 - val_loss: 1559.5856 - val_mae: 1559.5856 - val_mse: 19558628.0000\n",
            "Epoch 754/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1616.8104 - mae: 1616.8104 - mse: 18994014.0000 - val_loss: 1582.9390 - val_mae: 1582.9390 - val_mse: 20261586.0000\n",
            "Epoch 755/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1586.1046 - mae: 1586.1046 - mse: 19034682.0000 - val_loss: 1608.8904 - val_mae: 1608.8904 - val_mse: 20083314.0000\n",
            "Epoch 756/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1613.7611 - mae: 1613.7611 - mse: 18890982.0000 - val_loss: 1517.5923 - val_mae: 1517.5923 - val_mse: 19496794.0000\n",
            "Epoch 757/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1590.6583 - mae: 1590.6583 - mse: 19269556.0000 - val_loss: 1479.8744 - val_mae: 1479.8744 - val_mse: 19868296.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 758/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1640.5861 - mae: 1640.5861 - mse: 19612832.0000 - val_loss: 1541.9813 - val_mae: 1541.9813 - val_mse: 19439034.0000\n",
            "Epoch 759/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1587.6161 - mae: 1587.6161 - mse: 19152442.0000 - val_loss: 1895.7351 - val_mae: 1895.7351 - val_mse: 22764954.0000\n",
            "Epoch 760/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1566.2677 - mae: 1566.2677 - mse: 18722686.0000 - val_loss: 1649.9481 - val_mae: 1649.9481 - val_mse: 21193216.0000\n",
            "Epoch 761/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1645.1780 - mae: 1645.1780 - mse: 19577054.0000 - val_loss: 1674.9159 - val_mae: 1674.9159 - val_mse: 19724218.0000\n",
            "Epoch 762/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1622.6348 - mae: 1622.6348 - mse: 19175708.0000 - val_loss: 1589.8511 - val_mae: 1589.8511 - val_mse: 19469430.0000\n",
            "Epoch 763/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1609.7135 - mae: 1609.7135 - mse: 19120228.0000 - val_loss: 1606.6617 - val_mae: 1606.6617 - val_mse: 19645290.0000\n",
            "Epoch 764/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1601.9878 - mae: 1601.9878 - mse: 19266722.0000 - val_loss: 1908.5355 - val_mae: 1908.5355 - val_mse: 22092460.0000\n",
            "Epoch 765/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1602.0902 - mae: 1602.0902 - mse: 19084110.0000 - val_loss: 1697.9202 - val_mae: 1697.9202 - val_mse: 19003222.0000\n",
            "Epoch 766/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1664.6516 - mae: 1664.6516 - mse: 19469144.0000 - val_loss: 1477.5660 - val_mae: 1477.5660 - val_mse: 19799212.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 767/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1602.9823 - mae: 1602.9823 - mse: 19195768.0000 - val_loss: 1699.6925 - val_mae: 1699.6925 - val_mse: 18849254.0000\n",
            "Epoch 768/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1604.1558 - mae: 1604.1558 - mse: 19073448.0000 - val_loss: 2269.5134 - val_mae: 2269.5134 - val_mse: 19796780.0000\n",
            "Epoch 769/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1603.9791 - mae: 1603.9791 - mse: 18869496.0000 - val_loss: 1553.7748 - val_mae: 1553.7748 - val_mse: 19066092.0000\n",
            "Epoch 770/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1616.1195 - mae: 1616.1195 - mse: 19215882.0000 - val_loss: 1552.3719 - val_mae: 1552.3719 - val_mse: 19724226.0000\n",
            "Epoch 771/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1574.0217 - mae: 1574.0217 - mse: 19156190.0000 - val_loss: 1553.1074 - val_mae: 1553.1074 - val_mse: 19491986.0000\n",
            "Epoch 772/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.5719 - mae: 1603.5719 - mse: 18836270.0000 - val_loss: 1635.7507 - val_mae: 1635.7507 - val_mse: 20967244.0000\n",
            "Epoch 773/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1546.1017 - mae: 1546.1017 - mse: 18694384.0000 - val_loss: 1905.6838 - val_mae: 1905.6838 - val_mse: 21664424.0000\n",
            "Epoch 774/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1643.8848 - mae: 1643.8848 - mse: 19734830.0000 - val_loss: 1842.0387 - val_mae: 1842.0387 - val_mse: 19523478.0000\n",
            "Epoch 775/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1622.1089 - mae: 1622.1089 - mse: 19045866.0000 - val_loss: 1519.3794 - val_mae: 1519.3794 - val_mse: 20080818.0000\n",
            "Epoch 776/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1641.2957 - mae: 1641.2957 - mse: 19162580.0000 - val_loss: 1823.6582 - val_mae: 1823.6582 - val_mse: 21557618.0000\n",
            "Epoch 777/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1632.0938 - mae: 1632.0938 - mse: 19273512.0000 - val_loss: 1592.9432 - val_mae: 1592.9432 - val_mse: 19227322.0000\n",
            "Epoch 778/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1595.0050 - mae: 1595.0050 - mse: 19105116.0000 - val_loss: 1546.6191 - val_mae: 1546.6191 - val_mse: 19262158.0000\n",
            "Epoch 779/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1591.2982 - mae: 1591.2982 - mse: 19159240.0000 - val_loss: 1567.1630 - val_mae: 1567.1630 - val_mse: 19357858.0000\n",
            "Epoch 780/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1632.3193 - mae: 1632.3193 - mse: 19479134.0000 - val_loss: 1750.9861 - val_mae: 1750.9861 - val_mse: 19202642.0000\n",
            "Epoch 781/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1601.5020 - mae: 1601.5020 - mse: 18978598.0000 - val_loss: 1829.3734 - val_mae: 1829.3734 - val_mse: 21808282.0000\n",
            "Epoch 782/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1599.6407 - mae: 1599.6407 - mse: 18911796.0000 - val_loss: 1756.3110 - val_mae: 1756.3110 - val_mse: 21605226.0000\n",
            "Epoch 783/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1598.3016 - mae: 1598.3016 - mse: 19178568.0000 - val_loss: 1703.4048 - val_mae: 1703.4048 - val_mse: 19023496.0000\n",
            "Epoch 784/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1602.1479 - mae: 1602.1479 - mse: 19416446.0000 - val_loss: 1535.5023 - val_mae: 1535.5023 - val_mse: 20121556.0000\n",
            "Epoch 785/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1616.0988 - mae: 1616.0988 - mse: 19129142.0000 - val_loss: 1909.7173 - val_mae: 1909.7173 - val_mse: 21848222.0000\n",
            "Epoch 786/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1601.3312 - mae: 1601.3312 - mse: 19125926.0000 - val_loss: 1516.7583 - val_mae: 1516.7583 - val_mse: 20253332.0000\n",
            "Epoch 787/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.3690 - mae: 1554.3690 - mse: 19167382.0000 - val_loss: 1641.0122 - val_mae: 1641.0122 - val_mse: 20566212.0000\n",
            "Epoch 788/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1600.3208 - mae: 1600.3208 - mse: 18946782.0000 - val_loss: 1715.6608 - val_mae: 1715.6608 - val_mse: 19911980.0000\n",
            "Epoch 789/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1560.2078 - mae: 1560.2078 - mse: 18592070.0000 - val_loss: 2154.3740 - val_mae: 2154.3740 - val_mse: 23889094.0000\n",
            "Epoch 790/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1610.7179 - mae: 1610.7179 - mse: 19301122.0000 - val_loss: 1833.4971 - val_mae: 1833.4971 - val_mse: 21869248.0000\n",
            "Epoch 791/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1625.8950 - mae: 1625.8950 - mse: 19350374.0000 - val_loss: 1559.6188 - val_mae: 1559.6188 - val_mse: 20067836.0000\n",
            "Epoch 792/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1601.2596 - mae: 1601.2596 - mse: 19410196.0000 - val_loss: 1628.2740 - val_mae: 1628.2740 - val_mse: 20626600.0000\n",
            "Epoch 793/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1571.7935 - mae: 1571.7935 - mse: 19042082.0000 - val_loss: 1934.4497 - val_mae: 1934.4497 - val_mse: 22145576.0000\n",
            "Epoch 794/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1591.7505 - mae: 1591.7505 - mse: 18935706.0000 - val_loss: 1663.1954 - val_mae: 1663.1954 - val_mse: 21669438.0000\n",
            "Epoch 795/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1586.1783 - mae: 1586.1783 - mse: 18897184.0000 - val_loss: 1703.8693 - val_mae: 1703.8693 - val_mse: 21417338.0000\n",
            "Epoch 796/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1627.5010 - mae: 1627.5010 - mse: 19276968.0000 - val_loss: 2028.3772 - val_mae: 2028.3772 - val_mse: 20535718.0000\n",
            "Epoch 797/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1613.1434 - mae: 1613.1434 - mse: 19361318.0000 - val_loss: 1480.1145 - val_mae: 1480.1145 - val_mse: 19367474.0000\n",
            "Epoch 798/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1643.2312 - mae: 1643.2312 - mse: 19336970.0000 - val_loss: 2197.9712 - val_mae: 2197.9712 - val_mse: 24490640.0000\n",
            "Epoch 799/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1608.8148 - mae: 1608.8148 - mse: 19621872.0000 - val_loss: 1541.3052 - val_mae: 1541.3052 - val_mse: 20169720.0000\n",
            "Epoch 800/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1580.3373 - mae: 1580.3373 - mse: 19090004.0000 - val_loss: 1631.2646 - val_mae: 1631.2646 - val_mse: 20569854.0000\n",
            "Epoch 801/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1605.4790 - mae: 1605.4790 - mse: 19322474.0000 - val_loss: 1596.3755 - val_mae: 1596.3755 - val_mse: 18927168.0000\n",
            "Epoch 802/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1566.3685 - mae: 1566.3685 - mse: 18834940.0000 - val_loss: 2156.2390 - val_mae: 2156.2390 - val_mse: 24731988.0000\n",
            "Epoch 803/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1617.2635 - mae: 1617.2635 - mse: 19019750.0000 - val_loss: 1658.2588 - val_mae: 1658.2588 - val_mse: 20685836.0000\n",
            "Epoch 804/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1614.5671 - mae: 1614.5671 - mse: 19041300.0000 - val_loss: 1595.4247 - val_mae: 1595.4247 - val_mse: 20502312.0000\n",
            "Epoch 805/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1599.0687 - mae: 1599.0687 - mse: 19206318.0000 - val_loss: 1505.4906 - val_mae: 1505.4906 - val_mse: 19778912.0000\n",
            "Epoch 806/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1562.3916 - mae: 1562.3916 - mse: 18641532.0000 - val_loss: 1629.1519 - val_mae: 1629.1519 - val_mse: 19098322.0000\n",
            "Epoch 807/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1589.7129 - mae: 1589.7129 - mse: 19023628.0000 - val_loss: 1673.3702 - val_mae: 1673.3702 - val_mse: 20993584.0000\n",
            "Epoch 808/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1605.8043 - mae: 1605.8043 - mse: 19008674.0000 - val_loss: 1479.2970 - val_mae: 1479.2970 - val_mse: 19417318.0000\n",
            "Epoch 809/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1605.3878 - mae: 1605.3878 - mse: 19124226.0000 - val_loss: 1895.6079 - val_mae: 1895.6079 - val_mse: 19001772.0000\n",
            "Epoch 810/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1618.8969 - mae: 1618.8969 - mse: 19099126.0000 - val_loss: 1599.7418 - val_mae: 1599.7418 - val_mse: 20520688.0000\n",
            "Epoch 811/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.0865 - mae: 1593.0865 - mse: 19087822.0000 - val_loss: 2038.2860 - val_mae: 2038.2860 - val_mse: 22848924.0000\n",
            "Epoch 812/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1581.3019 - mae: 1581.3019 - mse: 19031794.0000 - val_loss: 2064.6245 - val_mae: 2064.6245 - val_mse: 22799640.0000\n",
            "Epoch 813/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1568.6996 - mae: 1568.6996 - mse: 18916546.0000 - val_loss: 1618.2456 - val_mae: 1618.2456 - val_mse: 19470898.0000\n",
            "Epoch 814/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1621.5381 - mae: 1621.5381 - mse: 19224138.0000 - val_loss: 1866.9786 - val_mae: 1866.9786 - val_mse: 19365142.0000\n",
            "Epoch 815/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1582.7031 - mae: 1582.7031 - mse: 19045772.0000 - val_loss: 1542.4805 - val_mae: 1542.4805 - val_mse: 19176414.0000\n",
            "Epoch 816/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1587.6875 - mae: 1587.6875 - mse: 19046380.0000 - val_loss: 1696.1213 - val_mae: 1696.1213 - val_mse: 20557498.0000\n",
            "Epoch 817/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1608.3557 - mae: 1608.3557 - mse: 19289626.0000 - val_loss: 1866.8066 - val_mae: 1866.8066 - val_mse: 21736646.0000\n",
            "Epoch 818/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1516.3000 - mae: 1516.3000 - mse: 18782270.0000 - val_loss: 1852.2118 - val_mae: 1852.2118 - val_mse: 22046560.0000\n",
            "Epoch 819/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1592.9247 - mae: 1592.9247 - mse: 18808596.0000 - val_loss: 2024.2158 - val_mae: 2024.2158 - val_mse: 22643082.0000\n",
            "Epoch 820/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1574.4940 - mae: 1574.4940 - mse: 18689984.0000 - val_loss: 1527.5432 - val_mae: 1527.5432 - val_mse: 20196654.0000\n",
            "Epoch 821/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1613.5193 - mae: 1613.5193 - mse: 18975788.0000 - val_loss: 1466.7914 - val_mae: 1466.7914 - val_mse: 19723432.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 822/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1579.0453 - mae: 1579.0453 - mse: 18923188.0000 - val_loss: 1645.6227 - val_mae: 1645.6227 - val_mse: 20646676.0000\n",
            "Epoch 823/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1608.9656 - mae: 1608.9656 - mse: 19140038.0000 - val_loss: 1502.0520 - val_mae: 1502.0520 - val_mse: 19412348.0000\n",
            "Epoch 824/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1574.5286 - mae: 1574.5286 - mse: 19011312.0000 - val_loss: 1507.8934 - val_mae: 1507.8934 - val_mse: 19315872.0000\n",
            "Epoch 825/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1584.5491 - mae: 1584.5491 - mse: 18707984.0000 - val_loss: 1547.2758 - val_mae: 1547.2758 - val_mse: 18964204.0000\n",
            "Epoch 826/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1543.4185 - mae: 1543.4185 - mse: 18554912.0000 - val_loss: 1642.9337 - val_mae: 1642.9337 - val_mse: 21542242.0000\n",
            "Epoch 827/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1575.6193 - mae: 1575.6193 - mse: 18938006.0000 - val_loss: 1574.7743 - val_mae: 1574.7743 - val_mse: 20345916.0000\n",
            "Epoch 828/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1608.7963 - mae: 1608.7963 - mse: 19328690.0000 - val_loss: 1681.5646 - val_mae: 1681.5646 - val_mse: 18922364.0000\n",
            "Epoch 829/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1567.7719 - mae: 1567.7719 - mse: 18671016.0000 - val_loss: 1797.8625 - val_mae: 1797.8625 - val_mse: 21857412.0000\n",
            "Epoch 830/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1580.8512 - mae: 1580.8512 - mse: 19031612.0000 - val_loss: 1682.0459 - val_mae: 1682.0459 - val_mse: 19220734.0000\n",
            "Epoch 831/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1584.6746 - mae: 1584.6746 - mse: 19272142.0000 - val_loss: 1523.0013 - val_mae: 1523.0013 - val_mse: 19133370.0000\n",
            "Epoch 832/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1567.0470 - mae: 1567.0470 - mse: 18916808.0000 - val_loss: 1553.8384 - val_mae: 1553.8384 - val_mse: 20437050.0000\n",
            "Epoch 833/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1583.2908 - mae: 1583.2908 - mse: 18788396.0000 - val_loss: 1638.1361 - val_mae: 1638.1361 - val_mse: 20361354.0000\n",
            "Epoch 834/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1618.6808 - mae: 1618.6808 - mse: 19040538.0000 - val_loss: 1543.3357 - val_mae: 1543.3357 - val_mse: 20232762.0000\n",
            "Epoch 835/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1594.4752 - mae: 1594.4752 - mse: 19396606.0000 - val_loss: 1524.8341 - val_mae: 1524.8341 - val_mse: 19956652.0000\n",
            "Epoch 836/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1568.1266 - mae: 1568.1266 - mse: 18901448.0000 - val_loss: 1644.6163 - val_mae: 1644.6163 - val_mse: 20200038.0000\n",
            "Epoch 837/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1617.5319 - mae: 1617.5319 - mse: 19203648.0000 - val_loss: 1687.8279 - val_mae: 1687.8279 - val_mse: 19030036.0000\n",
            "Epoch 838/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1561.9846 - mae: 1561.9846 - mse: 18865576.0000 - val_loss: 1688.4395 - val_mae: 1688.4395 - val_mse: 21053242.0000\n",
            "Epoch 839/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1607.0657 - mae: 1607.0657 - mse: 18970640.0000 - val_loss: 1819.1575 - val_mae: 1819.1575 - val_mse: 22160934.0000\n",
            "Epoch 840/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1578.6155 - mae: 1578.6155 - mse: 18939896.0000 - val_loss: 1732.7999 - val_mae: 1732.7999 - val_mse: 21145492.0000\n",
            "Epoch 841/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1550.4425 - mae: 1550.4425 - mse: 18895052.0000 - val_loss: 1919.4265 - val_mae: 1919.4265 - val_mse: 19115766.0000\n",
            "Epoch 842/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1581.6671 - mae: 1581.6671 - mse: 18726524.0000 - val_loss: 1773.2766 - val_mae: 1773.2766 - val_mse: 18874316.0000\n",
            "Epoch 843/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1642.9558 - mae: 1642.9558 - mse: 19526902.0000 - val_loss: 1698.1412 - val_mae: 1698.1412 - val_mse: 20890494.0000\n",
            "Epoch 844/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1541.3842 - mae: 1541.3842 - mse: 18856484.0000 - val_loss: 1747.4011 - val_mae: 1747.4011 - val_mse: 19056730.0000\n",
            "Epoch 845/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1565.3572 - mae: 1565.3572 - mse: 19084366.0000 - val_loss: 1769.8651 - val_mae: 1769.8651 - val_mse: 22044358.0000\n",
            "Epoch 846/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.2925 - mae: 1605.2925 - mse: 18861240.0000 - val_loss: 1480.5817 - val_mae: 1480.5817 - val_mse: 19533088.0000\n",
            "Epoch 847/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1576.4823 - mae: 1576.4823 - mse: 19026568.0000 - val_loss: 2322.5679 - val_mae: 2322.5679 - val_mse: 25986674.0000\n",
            "Epoch 848/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1609.4702 - mae: 1609.4702 - mse: 19114882.0000 - val_loss: 1738.5272 - val_mae: 1738.5272 - val_mse: 18990760.0000\n",
            "Epoch 849/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1540.6022 - mae: 1540.6022 - mse: 18735562.0000 - val_loss: 2121.3210 - val_mae: 2121.3210 - val_mse: 24057624.0000\n",
            "Epoch 850/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1584.5735 - mae: 1584.5735 - mse: 19005950.0000 - val_loss: 1636.3540 - val_mae: 1636.3540 - val_mse: 20793056.0000\n",
            "Epoch 851/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1623.1003 - mae: 1623.1003 - mse: 19241438.0000 - val_loss: 1763.7708 - val_mae: 1763.7708 - val_mse: 21212244.0000\n",
            "Epoch 852/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1591.6694 - mae: 1591.6694 - mse: 18862090.0000 - val_loss: 1947.9983 - val_mae: 1947.9983 - val_mse: 20233828.0000\n",
            "Epoch 853/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1552.7151 - mae: 1552.7151 - mse: 18824184.0000 - val_loss: 1462.9381 - val_mae: 1462.9381 - val_mse: 19594632.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 854/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1628.9667 - mae: 1628.9667 - mse: 19350792.0000 - val_loss: 1622.4731 - val_mae: 1622.4731 - val_mse: 19009184.0000\n",
            "Epoch 855/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1569.7803 - mae: 1569.7803 - mse: 18777074.0000 - val_loss: 1456.9176 - val_mae: 1456.9176 - val_mse: 19949694.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 856/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1564.5214 - mae: 1564.5214 - mse: 18736550.0000 - val_loss: 1639.9288 - val_mae: 1639.9288 - val_mse: 21028436.0000\n",
            "Epoch 857/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1535.3357 - mae: 1535.3357 - mse: 18601494.0000 - val_loss: 1664.8510 - val_mae: 1664.8510 - val_mse: 20767928.0000\n",
            "Epoch 858/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1678.3872 - mae: 1678.3872 - mse: 19851762.0000 - val_loss: 1713.7375 - val_mae: 1713.7375 - val_mse: 18862264.0000\n",
            "Epoch 859/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1556.5697 - mae: 1556.5697 - mse: 18569384.0000 - val_loss: 1837.6036 - val_mae: 1837.6036 - val_mse: 19046078.0000\n",
            "Epoch 860/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1562.5977 - mae: 1562.5977 - mse: 18651942.0000 - val_loss: 1489.2577 - val_mae: 1489.2577 - val_mse: 19658858.0000\n",
            "Epoch 861/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1594.5431 - mae: 1594.5431 - mse: 19248772.0000 - val_loss: 1645.7007 - val_mae: 1645.7007 - val_mse: 19087140.0000\n",
            "Epoch 862/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1543.8364 - mae: 1543.8364 - mse: 18711938.0000 - val_loss: 1572.9768 - val_mae: 1572.9768 - val_mse: 20366638.0000\n",
            "Epoch 863/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.3975 - mae: 1588.3975 - mse: 19109406.0000 - val_loss: 1572.1429 - val_mae: 1572.1429 - val_mse: 19201874.0000\n",
            "Epoch 864/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1566.0433 - mae: 1566.0433 - mse: 18771880.0000 - val_loss: 1489.5820 - val_mae: 1489.5820 - val_mse: 20246450.0000\n",
            "Epoch 865/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1547.6213 - mae: 1547.6213 - mse: 18828684.0000 - val_loss: 1474.4906 - val_mae: 1474.4906 - val_mse: 19287856.0000\n",
            "Epoch 866/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1590.1000 - mae: 1590.1000 - mse: 18942900.0000 - val_loss: 1579.0627 - val_mae: 1579.0627 - val_mse: 20142570.0000\n",
            "Epoch 867/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1558.4753 - mae: 1558.4753 - mse: 18691210.0000 - val_loss: 1689.2144 - val_mae: 1689.2144 - val_mse: 18794690.0000\n",
            "Epoch 868/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.8777 - mae: 1616.8777 - mse: 19065720.0000 - val_loss: 1631.1772 - val_mae: 1631.1772 - val_mse: 18935312.0000\n",
            "Epoch 869/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1555.7930 - mae: 1555.7930 - mse: 18896662.0000 - val_loss: 2145.6257 - val_mae: 2145.6257 - val_mse: 23408332.0000\n",
            "Epoch 870/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1567.1741 - mae: 1567.1741 - mse: 18870118.0000 - val_loss: 1507.8845 - val_mae: 1507.8845 - val_mse: 19465274.0000\n",
            "Epoch 871/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1571.4240 - mae: 1571.4240 - mse: 18740930.0000 - val_loss: 1594.7296 - val_mae: 1594.7296 - val_mse: 20605396.0000\n",
            "Epoch 872/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1583.6414 - mae: 1583.6414 - mse: 18867862.0000 - val_loss: 1611.6925 - val_mae: 1611.6925 - val_mse: 18870862.0000\n",
            "Epoch 873/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1610.6339 - mae: 1610.6339 - mse: 19033068.0000 - val_loss: 1597.2515 - val_mae: 1597.2515 - val_mse: 19559666.0000\n",
            "Epoch 874/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1585.2111 - mae: 1585.2111 - mse: 19407320.0000 - val_loss: 1581.3750 - val_mae: 1581.3750 - val_mse: 19911264.0000\n",
            "Epoch 875/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1604.6802 - mae: 1604.6802 - mse: 19232414.0000 - val_loss: 1576.2008 - val_mae: 1576.2008 - val_mse: 20422324.0000\n",
            "Epoch 876/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1555.4817 - mae: 1555.4817 - mse: 18894076.0000 - val_loss: 1880.0969 - val_mae: 1880.0969 - val_mse: 23727254.0000\n",
            "Epoch 877/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1587.7545 - mae: 1587.7545 - mse: 19058638.0000 - val_loss: 1676.0887 - val_mae: 1676.0887 - val_mse: 18822120.0000\n",
            "Epoch 878/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1537.2693 - mae: 1537.2693 - mse: 18482576.0000 - val_loss: 1817.0068 - val_mae: 1817.0068 - val_mse: 22192874.0000\n",
            "Epoch 879/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1629.1147 - mae: 1629.1147 - mse: 19443520.0000 - val_loss: 1515.6091 - val_mae: 1515.6091 - val_mse: 20058348.0000\n",
            "Epoch 880/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1546.7800 - mae: 1546.7800 - mse: 18685786.0000 - val_loss: 1473.4702 - val_mae: 1473.4702 - val_mse: 19704950.0000\n",
            "Epoch 881/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1607.3944 - mae: 1607.3944 - mse: 18968940.0000 - val_loss: 1693.7357 - val_mae: 1693.7357 - val_mse: 21437230.0000\n",
            "Epoch 882/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1558.4329 - mae: 1558.4329 - mse: 19001474.0000 - val_loss: 1561.7036 - val_mae: 1561.7036 - val_mse: 20125744.0000\n",
            "Epoch 883/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1574.2012 - mae: 1574.2012 - mse: 19080184.0000 - val_loss: 1785.0745 - val_mae: 1785.0745 - val_mse: 21666802.0000\n",
            "Epoch 884/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1572.4902 - mae: 1572.4902 - mse: 18660758.0000 - val_loss: 1715.7573 - val_mae: 1715.7573 - val_mse: 18818702.0000\n",
            "Epoch 885/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1566.2218 - mae: 1566.2218 - mse: 18679964.0000 - val_loss: 1591.2140 - val_mae: 1591.2140 - val_mse: 20556504.0000\n",
            "Epoch 886/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1586.6195 - mae: 1586.6195 - mse: 19071700.0000 - val_loss: 2265.1067 - val_mae: 2265.1067 - val_mse: 21007724.0000\n",
            "Epoch 887/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.0969 - mae: 1616.0969 - mse: 19381608.0000 - val_loss: 1520.1547 - val_mae: 1520.1547 - val_mse: 20278592.0000\n",
            "Epoch 888/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1558.9280 - mae: 1558.9280 - mse: 18745120.0000 - val_loss: 1445.4263 - val_mae: 1445.4263 - val_mse: 19842418.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 889/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1609.1204 - mae: 1609.1204 - mse: 19012198.0000 - val_loss: 1738.3490 - val_mae: 1738.3490 - val_mse: 19022956.0000\n",
            "Epoch 890/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1557.7617 - mae: 1557.7617 - mse: 18634344.0000 - val_loss: 2149.5510 - val_mae: 2149.5510 - val_mse: 23738466.0000\n",
            "Epoch 891/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1557.1235 - mae: 1557.1235 - mse: 18826022.0000 - val_loss: 1560.8353 - val_mae: 1560.8353 - val_mse: 19962020.0000\n",
            "Epoch 892/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1584.8661 - mae: 1584.8661 - mse: 18766136.0000 - val_loss: 1883.7379 - val_mae: 1883.7379 - val_mse: 19058274.0000\n",
            "Epoch 893/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1601.3207 - mae: 1601.3207 - mse: 19264790.0000 - val_loss: 1664.0466 - val_mae: 1664.0466 - val_mse: 21217800.0000\n",
            "Epoch 894/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1553.3491 - mae: 1553.3491 - mse: 18936498.0000 - val_loss: 2148.4387 - val_mae: 2148.4387 - val_mse: 23383968.0000\n",
            "Epoch 895/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1608.4575 - mae: 1608.4575 - mse: 19106888.0000 - val_loss: 1567.5400 - val_mae: 1567.5400 - val_mse: 20567564.0000\n",
            "Epoch 896/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1533.8484 - mae: 1533.8484 - mse: 18585306.0000 - val_loss: 1530.6136 - val_mae: 1530.6136 - val_mse: 19755234.0000\n",
            "Epoch 897/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1560.3271 - mae: 1560.3271 - mse: 18908028.0000 - val_loss: 1853.0767 - val_mae: 1853.0767 - val_mse: 21790792.0000\n",
            "Epoch 898/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1587.4191 - mae: 1587.4191 - mse: 19103678.0000 - val_loss: 1834.2715 - val_mae: 1834.2715 - val_mse: 21865306.0000\n",
            "Epoch 899/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1554.5781 - mae: 1554.5781 - mse: 18868580.0000 - val_loss: 1509.8142 - val_mae: 1509.8142 - val_mse: 19435244.0000\n",
            "Epoch 900/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1563.0803 - mae: 1563.0803 - mse: 18948904.0000 - val_loss: 1556.1014 - val_mae: 1556.1014 - val_mse: 19450268.0000\n",
            "Epoch 901/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1596.9169 - mae: 1596.9169 - mse: 19653890.0000 - val_loss: 1466.3518 - val_mae: 1466.3518 - val_mse: 20050488.0000\n",
            "Epoch 902/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1542.5786 - mae: 1542.5786 - mse: 18766768.0000 - val_loss: 1999.1315 - val_mae: 1999.1315 - val_mse: 22389212.0000\n",
            "Epoch 903/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1544.3265 - mae: 1544.3265 - mse: 19008292.0000 - val_loss: 1848.4792 - val_mae: 1848.4792 - val_mse: 19072924.0000\n",
            "Epoch 904/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1601.9352 - mae: 1601.9352 - mse: 18588672.0000 - val_loss: 1804.0315 - val_mae: 1804.0315 - val_mse: 21996902.0000\n",
            "Epoch 905/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1555.7953 - mae: 1555.7953 - mse: 18812084.0000 - val_loss: 1553.9681 - val_mae: 1553.9681 - val_mse: 19469840.0000\n",
            "Epoch 906/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1569.6041 - mae: 1569.6041 - mse: 18718178.0000 - val_loss: 1508.0695 - val_mae: 1508.0695 - val_mse: 19127702.0000\n",
            "Epoch 907/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1550.9641 - mae: 1550.9641 - mse: 18672276.0000 - val_loss: 1494.7733 - val_mae: 1494.7733 - val_mse: 19779138.0000\n",
            "Epoch 908/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1552.6019 - mae: 1552.6019 - mse: 18948140.0000 - val_loss: 1592.1926 - val_mae: 1592.1926 - val_mse: 20134798.0000\n",
            "Epoch 909/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1585.0050 - mae: 1585.0050 - mse: 18917810.0000 - val_loss: 1648.5403 - val_mae: 1648.5403 - val_mse: 18955272.0000\n",
            "Epoch 910/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1608.8282 - mae: 1608.8282 - mse: 19117242.0000 - val_loss: 1623.4796 - val_mae: 1623.4796 - val_mse: 18992740.0000\n",
            "Epoch 911/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1537.9896 - mae: 1537.9896 - mse: 18547998.0000 - val_loss: 1649.5608 - val_mae: 1649.5608 - val_mse: 20891858.0000\n",
            "Epoch 912/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.1913 - mae: 1588.1913 - mse: 18860984.0000 - val_loss: 1637.4530 - val_mae: 1637.4530 - val_mse: 18823610.0000\n",
            "Epoch 913/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1587.9897 - mae: 1587.9897 - mse: 19085984.0000 - val_loss: 1894.9149 - val_mae: 1894.9149 - val_mse: 18827548.0000\n",
            "Epoch 914/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.9531 - mae: 1554.9531 - mse: 18940620.0000 - val_loss: 1662.2247 - val_mae: 1662.2247 - val_mse: 20575648.0000\n",
            "Epoch 915/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1570.5563 - mae: 1570.5563 - mse: 18876718.0000 - val_loss: 2003.5662 - val_mae: 2003.5662 - val_mse: 23218952.0000\n",
            "Epoch 916/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1576.4540 - mae: 1576.4540 - mse: 19186882.0000 - val_loss: 1571.0435 - val_mae: 1571.0435 - val_mse: 20347782.0000\n",
            "Epoch 917/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1564.3964 - mae: 1564.3964 - mse: 18766880.0000 - val_loss: 1476.5330 - val_mae: 1476.5330 - val_mse: 20098598.0000\n",
            "Epoch 918/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1582.2031 - mae: 1582.2031 - mse: 19013254.0000 - val_loss: 1521.0549 - val_mae: 1521.0549 - val_mse: 20253426.0000\n",
            "Epoch 919/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1579.5741 - mae: 1579.5741 - mse: 18981338.0000 - val_loss: 1514.4896 - val_mae: 1514.4896 - val_mse: 19265492.0000\n",
            "Epoch 920/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1581.5848 - mae: 1581.5848 - mse: 18967424.0000 - val_loss: 1506.1943 - val_mae: 1506.1943 - val_mse: 19098320.0000\n",
            "Epoch 921/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1583.3058 - mae: 1583.3058 - mse: 19008428.0000 - val_loss: 1672.6554 - val_mae: 1672.6554 - val_mse: 19470598.0000\n",
            "Epoch 922/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1579.4745 - mae: 1579.4745 - mse: 19155766.0000 - val_loss: 1493.0365 - val_mae: 1493.0365 - val_mse: 19260988.0000\n",
            "Epoch 923/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1608.9091 - mae: 1608.9091 - mse: 19081114.0000 - val_loss: 1469.3752 - val_mae: 1469.3752 - val_mse: 19145614.0000\n",
            "Epoch 924/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1597.2103 - mae: 1597.2103 - mse: 19067130.0000 - val_loss: 1749.5321 - val_mae: 1749.5321 - val_mse: 18845076.0000\n",
            "Epoch 925/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1559.2540 - mae: 1559.2540 - mse: 18928118.0000 - val_loss: 2064.0054 - val_mae: 2064.0054 - val_mse: 19745882.0000\n",
            "Epoch 926/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1575.4559 - mae: 1575.4559 - mse: 18969126.0000 - val_loss: 1668.8130 - val_mae: 1668.8130 - val_mse: 18717718.0000\n",
            "Epoch 927/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.6937 - mae: 1588.6937 - mse: 19155336.0000 - val_loss: 1463.5392 - val_mae: 1463.5392 - val_mse: 19229688.0000\n",
            "Epoch 928/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1564.3365 - mae: 1564.3365 - mse: 18710092.0000 - val_loss: 1666.0105 - val_mae: 1666.0105 - val_mse: 18997496.0000\n",
            "Epoch 929/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1545.3140 - mae: 1545.3140 - mse: 19022128.0000 - val_loss: 1968.5013 - val_mae: 1968.5013 - val_mse: 22259866.0000\n",
            "Epoch 930/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1562.5226 - mae: 1562.5226 - mse: 19023700.0000 - val_loss: 1689.4017 - val_mae: 1689.4017 - val_mse: 22063192.0000\n",
            "Epoch 931/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1604.8365 - mae: 1604.8365 - mse: 19051244.0000 - val_loss: 1484.9789 - val_mae: 1484.9789 - val_mse: 20109962.0000\n",
            "Epoch 932/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1529.9600 - mae: 1529.9600 - mse: 18717200.0000 - val_loss: 1554.3723 - val_mae: 1554.3723 - val_mse: 19581260.0000\n",
            "Epoch 933/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1591.8081 - mae: 1591.8081 - mse: 19121674.0000 - val_loss: 1521.5172 - val_mae: 1521.5172 - val_mse: 19402422.0000\n",
            "Epoch 934/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1549.8467 - mae: 1549.8467 - mse: 18817742.0000 - val_loss: 1874.0424 - val_mae: 1874.0424 - val_mse: 22362816.0000\n",
            "Epoch 935/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1557.1219 - mae: 1557.1219 - mse: 18892082.0000 - val_loss: 1655.8563 - val_mae: 1655.8563 - val_mse: 18682912.0000\n",
            "Epoch 936/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1584.0027 - mae: 1584.0027 - mse: 18886316.0000 - val_loss: 1530.9866 - val_mae: 1530.9866 - val_mse: 20039642.0000\n",
            "Epoch 937/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1528.2456 - mae: 1528.2456 - mse: 19102694.0000 - val_loss: 2056.8286 - val_mae: 2056.8286 - val_mse: 23171680.0000\n",
            "Epoch 938/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1560.5382 - mae: 1560.5382 - mse: 18674312.0000 - val_loss: 1508.1227 - val_mae: 1508.1227 - val_mse: 20044932.0000\n",
            "Epoch 939/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1589.8137 - mae: 1589.8137 - mse: 18974078.0000 - val_loss: 1593.6902 - val_mae: 1593.6902 - val_mse: 20293596.0000\n",
            "Epoch 940/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1598.8613 - mae: 1598.8613 - mse: 19250436.0000 - val_loss: 1965.2113 - val_mae: 1965.2113 - val_mse: 18936622.0000\n",
            "Epoch 941/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1560.8693 - mae: 1560.8693 - mse: 18729822.0000 - val_loss: 1468.9121 - val_mae: 1468.9121 - val_mse: 19737714.0000\n",
            "Epoch 942/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1517.8171 - mae: 1517.8171 - mse: 18455410.0000 - val_loss: 1580.3213 - val_mae: 1580.3213 - val_mse: 20237900.0000\n",
            "Epoch 943/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.0537 - mae: 1588.0537 - mse: 18758030.0000 - val_loss: 1710.7709 - val_mae: 1710.7709 - val_mse: 19039262.0000\n",
            "Epoch 944/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1570.1941 - mae: 1570.1941 - mse: 19072198.0000 - val_loss: 1510.5975 - val_mae: 1510.5975 - val_mse: 20063266.0000\n",
            "Epoch 945/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1527.9817 - mae: 1527.9817 - mse: 18513648.0000 - val_loss: 1853.3566 - val_mae: 1853.3566 - val_mse: 19050098.0000\n",
            "Epoch 946/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1570.2606 - mae: 1570.2606 - mse: 19162072.0000 - val_loss: 1559.2260 - val_mae: 1559.2260 - val_mse: 19720602.0000\n",
            "Epoch 947/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1501.4169 - mae: 1501.4169 - mse: 18336428.0000 - val_loss: 1656.7089 - val_mae: 1656.7089 - val_mse: 18801264.0000\n",
            "Epoch 948/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1557.7773 - mae: 1557.7773 - mse: 18693952.0000 - val_loss: 1865.6013 - val_mae: 1865.6013 - val_mse: 22125706.0000\n",
            "Epoch 949/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1579.1572 - mae: 1579.1572 - mse: 19101580.0000 - val_loss: 1915.0537 - val_mae: 1915.0537 - val_mse: 19531484.0000\n",
            "Epoch 950/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1575.8976 - mae: 1575.8976 - mse: 18669662.0000 - val_loss: 1567.5304 - val_mae: 1567.5304 - val_mse: 18855896.0000\n",
            "Epoch 951/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1591.2922 - mae: 1591.2922 - mse: 19166858.0000 - val_loss: 1677.7872 - val_mae: 1677.7872 - val_mse: 18671326.0000\n",
            "Epoch 952/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1523.6080 - mae: 1523.6080 - mse: 18782898.0000 - val_loss: 1868.7412 - val_mae: 1868.7412 - val_mse: 18927254.0000\n",
            "Epoch 953/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1561.0796 - mae: 1561.0796 - mse: 18800174.0000 - val_loss: 1465.0717 - val_mae: 1465.0717 - val_mse: 19465858.0000\n",
            "Epoch 954/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1555.6509 - mae: 1555.6509 - mse: 18851480.0000 - val_loss: 2062.5161 - val_mae: 2062.5161 - val_mse: 20266496.0000\n",
            "Epoch 955/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1575.6964 - mae: 1575.6964 - mse: 19072946.0000 - val_loss: 1564.9340 - val_mae: 1564.9340 - val_mse: 20583618.0000\n",
            "Epoch 956/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1569.1688 - mae: 1569.1688 - mse: 18620388.0000 - val_loss: 1986.3823 - val_mae: 1986.3823 - val_mse: 19122780.0000\n",
            "Epoch 957/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1547.3011 - mae: 1547.3011 - mse: 18744446.0000 - val_loss: 1831.9205 - val_mae: 1831.9205 - val_mse: 21634784.0000\n",
            "Epoch 958/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1602.2509 - mae: 1602.2509 - mse: 19028316.0000 - val_loss: 1687.0240 - val_mae: 1687.0240 - val_mse: 18943544.0000\n",
            "Epoch 959/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1541.1586 - mae: 1541.1586 - mse: 18906486.0000 - val_loss: 1553.8265 - val_mae: 1553.8265 - val_mse: 19249334.0000\n",
            "Epoch 960/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1535.2068 - mae: 1535.2068 - mse: 18902676.0000 - val_loss: 1534.2882 - val_mae: 1534.2882 - val_mse: 18954208.0000\n",
            "Epoch 961/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1619.4552 - mae: 1619.4552 - mse: 19770118.0000 - val_loss: 1694.5261 - val_mae: 1694.5261 - val_mse: 18804018.0000\n",
            "Epoch 962/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1537.7235 - mae: 1537.7235 - mse: 18374036.0000 - val_loss: 1512.4962 - val_mae: 1512.4962 - val_mse: 19883480.0000\n",
            "Epoch 963/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1572.7722 - mae: 1572.7722 - mse: 19039508.0000 - val_loss: 1992.6111 - val_mae: 1992.6111 - val_mse: 19458416.0000\n",
            "Epoch 964/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1581.4038 - mae: 1581.4038 - mse: 19059276.0000 - val_loss: 1452.6270 - val_mae: 1452.6270 - val_mse: 19401118.0000\n",
            "Epoch 965/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1525.5818 - mae: 1525.5818 - mse: 18554636.0000 - val_loss: 2111.3394 - val_mae: 2111.3394 - val_mse: 23597266.0000\n",
            "Epoch 966/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1566.9019 - mae: 1566.9019 - mse: 19088352.0000 - val_loss: 1533.4843 - val_mae: 1533.4843 - val_mse: 20002304.0000\n",
            "Epoch 967/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1550.3489 - mae: 1550.3489 - mse: 19016958.0000 - val_loss: 1704.6755 - val_mae: 1704.6755 - val_mse: 21331822.0000\n",
            "Epoch 968/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.2867 - mae: 1554.2867 - mse: 18766014.0000 - val_loss: 1481.3662 - val_mae: 1481.3662 - val_mse: 19344728.0000\n",
            "Epoch 969/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1552.2599 - mae: 1552.2599 - mse: 18831478.0000 - val_loss: 1552.7584 - val_mae: 1552.7584 - val_mse: 20451556.0000\n",
            "Epoch 970/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1566.2150 - mae: 1566.2150 - mse: 18915942.0000 - val_loss: 1899.2646 - val_mae: 1899.2646 - val_mse: 19339668.0000\n",
            "Epoch 971/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1547.5795 - mae: 1547.5795 - mse: 18910408.0000 - val_loss: 1570.1323 - val_mae: 1570.1323 - val_mse: 19197070.0000\n",
            "Epoch 972/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1549.5504 - mae: 1549.5504 - mse: 18589258.0000 - val_loss: 1527.6958 - val_mae: 1527.6958 - val_mse: 19786858.0000\n",
            "Epoch 973/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1546.0745 - mae: 1546.0745 - mse: 18715722.0000 - val_loss: 1566.6189 - val_mae: 1566.6189 - val_mse: 20676000.0000\n",
            "Epoch 974/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1560.8298 - mae: 1560.8298 - mse: 18911566.0000 - val_loss: 1627.7476 - val_mae: 1627.7476 - val_mse: 20942630.0000\n",
            "Epoch 975/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1565.4077 - mae: 1565.4077 - mse: 19149864.0000 - val_loss: 1492.2852 - val_mae: 1492.2852 - val_mse: 20199544.0000\n",
            "Epoch 976/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1573.7844 - mae: 1573.7844 - mse: 18776818.0000 - val_loss: 1544.6013 - val_mae: 1544.6013 - val_mse: 19939038.0000\n",
            "Epoch 977/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.1152 - mae: 1554.1152 - mse: 18811888.0000 - val_loss: 1789.7167 - val_mae: 1789.7167 - val_mse: 21545666.0000\n",
            "Epoch 978/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1544.6207 - mae: 1544.6207 - mse: 18647816.0000 - val_loss: 1745.1631 - val_mae: 1745.1631 - val_mse: 21245670.0000\n",
            "Epoch 979/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1537.9875 - mae: 1537.9875 - mse: 18661076.0000 - val_loss: 1851.9418 - val_mae: 1851.9418 - val_mse: 19110610.0000\n",
            "Epoch 980/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1544.4305 - mae: 1544.4305 - mse: 18666212.0000 - val_loss: 1812.0349 - val_mae: 1812.0349 - val_mse: 18838338.0000\n",
            "Epoch 981/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1600.6044 - mae: 1600.6044 - mse: 18898684.0000 - val_loss: 1930.9447 - val_mae: 1930.9447 - val_mse: 19642796.0000\n",
            "Epoch 982/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1566.3989 - mae: 1566.3989 - mse: 18900262.0000 - val_loss: 1900.8827 - val_mae: 1900.8827 - val_mse: 22480264.0000\n",
            "Epoch 983/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1553.4651 - mae: 1553.4651 - mse: 19219466.0000 - val_loss: 1524.4241 - val_mae: 1524.4241 - val_mse: 19228328.0000\n",
            "Epoch 984/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1553.1587 - mae: 1553.1587 - mse: 18573236.0000 - val_loss: 1518.2205 - val_mae: 1518.2205 - val_mse: 19739218.0000\n",
            "Epoch 985/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1570.6443 - mae: 1570.6443 - mse: 18892266.0000 - val_loss: 1545.1884 - val_mae: 1545.1884 - val_mse: 20457620.0000\n",
            "Epoch 986/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1560.7679 - mae: 1560.7679 - mse: 18831094.0000 - val_loss: 1665.5306 - val_mae: 1665.5306 - val_mse: 19072294.0000\n",
            "Epoch 987/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1552.5878 - mae: 1552.5878 - mse: 18867576.0000 - val_loss: 1530.5726 - val_mae: 1530.5726 - val_mse: 20316552.0000\n",
            "Epoch 988/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1533.3308 - mae: 1533.3308 - mse: 18581182.0000 - val_loss: 1641.2250 - val_mae: 1641.2250 - val_mse: 20296756.0000\n",
            "Epoch 989/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.4946 - mae: 1593.4946 - mse: 19076020.0000 - val_loss: 1416.1749 - val_mae: 1416.1749 - val_mse: 19640822.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 990/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1514.2418 - mae: 1514.2418 - mse: 18448124.0000 - val_loss: 1671.8326 - val_mae: 1671.8326 - val_mse: 21598668.0000\n",
            "Epoch 991/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1556.8938 - mae: 1556.8938 - mse: 19055194.0000 - val_loss: 1644.5442 - val_mae: 1644.5442 - val_mse: 19172826.0000\n",
            "Epoch 992/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1550.7688 - mae: 1550.7688 - mse: 18578554.0000 - val_loss: 1752.4878 - val_mae: 1752.4878 - val_mse: 18963290.0000\n",
            "Epoch 993/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1575.9849 - mae: 1575.9849 - mse: 18754502.0000 - val_loss: 1708.4642 - val_mae: 1708.4642 - val_mse: 21002836.0000\n",
            "Epoch 994/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1582.7036 - mae: 1582.7036 - mse: 19723412.0000 - val_loss: 1805.2142 - val_mae: 1805.2142 - val_mse: 19137908.0000\n",
            "Epoch 995/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1568.5372 - mae: 1568.5372 - mse: 18870770.0000 - val_loss: 1760.9308 - val_mae: 1760.9308 - val_mse: 18882218.0000\n",
            "Epoch 996/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.5746 - mae: 1554.5746 - mse: 18977998.0000 - val_loss: 1566.1899 - val_mae: 1566.1899 - val_mse: 18954188.0000\n",
            "Epoch 997/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1545.1969 - mae: 1545.1969 - mse: 18950894.0000 - val_loss: 1447.6814 - val_mae: 1447.6814 - val_mse: 19678328.0000\n",
            "Epoch 998/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1568.8450 - mae: 1568.8450 - mse: 19033160.0000 - val_loss: 1511.0488 - val_mae: 1511.0488 - val_mse: 20075728.0000\n",
            "Epoch 999/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1561.2166 - mae: 1561.2166 - mse: 18839920.0000 - val_loss: 1453.2164 - val_mae: 1453.2164 - val_mse: 19396756.0000\n",
            "Epoch 1000/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1513.6538 - mae: 1513.6538 - mse: 18495932.0000 - val_loss: 1440.2708 - val_mae: 1440.2708 - val_mse: 19739610.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "dbae2307-e851-4b28-fd21-8f398f65f91b"
      },
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 2054.5286 - mae: 2054.5286 - mse: 34295712.0000\n",
            "Testing set Mean Abs Error: 2054.53 expenses\n",
            "You passed the challenge. Great job!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}